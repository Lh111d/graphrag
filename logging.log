2024-10-23 16:11:56,531 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://198.18.0.1:5000
2024-10-23 16:11:56,531 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-23 16:11:56,531 - werkzeug - INFO -  * Restarting with stat
2024-10-23 16:12:02,476 - werkzeug - WARNING -  * Debugger is active!
2024-10-23 16:12:02,477 - werkzeug - INFO -  * Debugger PIN: 683-701-297
2024-10-23 16:13:39,226 - werkzeug - INFO -  * Detected change in 'D:\\code\\grapgrag_flask\\test.py', reloading
2024-10-23 16:13:39,642 - werkzeug - INFO -  * Restarting with stat
2024-10-23 16:13:53,104 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:5000
 * Running on http://198.18.0.1:5000
2024-10-23 16:13:53,104 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-23 16:13:53,104 - werkzeug - INFO -  * Restarting with stat
2024-10-23 16:13:58,880 - werkzeug - WARNING -  * Debugger is active!
2024-10-23 16:13:58,884 - werkzeug - INFO -  * Debugger PIN: 683-701-297
2024-10-23 16:18:46,682 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-23 16:18:46,683 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-23 16:19:11,547 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-23 16:19:11,548 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-23 16:19:11,548 - werkzeug - INFO -  * Restarting with stat
2024-10-23 16:19:17,621 - werkzeug - WARNING -  * Debugger is active!
2024-10-23 16:19:17,622 - werkzeug - INFO -  * Debugger PIN: 683-701-297
2024-10-23 16:19:43,495 - werkzeug - INFO -  * Detected change in 'D:\\code\\grapgrag_flask\\main.py', reloading
2024-10-23 16:19:43,962 - werkzeug - INFO -  * Restarting with stat
2024-10-23 16:19:50,063 - werkzeug - WARNING -  * Debugger is active!
2024-10-23 16:19:50,064 - werkzeug - INFO -  * Debugger PIN: 683-701-297
2024-10-23 16:19:56,095 - root - INFO - YAML ÎÄ¼þÒÑÖØÐÂÐ´Èë³É¹¦£¡
2024-10-23 16:19:56,096 - root - INFO - .env file has been updated at: ./rag\.env
2024-10-23 16:19:56,098 - werkzeug - INFO - 127.0.0.1 - - [23/Oct/2024 16:19:56] "GET /graphrag/init HTTP/1.1" 200 -
2024-10-23 16:20:54,166 - werkzeug - INFO -  * Detected change in 'D:\\code\\grapgrag_flask\\main.py', reloading
2024-10-23 16:20:54,622 - werkzeug - INFO -  * Restarting with stat
2024-10-23 16:21:00,621 - werkzeug - WARNING -  * Debugger is active!
2024-10-23 16:21:00,623 - werkzeug - INFO -  * Debugger PIN: 683-701-297
2024-10-23 16:21:02,171 - root - INFO - YAML ÎÄ¼þÒÑÖØÐÂÐ´Èë³É¹¦£¡
2024-10-23 16:21:02,171 - root - INFO - .env file has been updated at: ./rag\.env
2024-10-23 16:21:02,176 - root - ERROR - Error in indexer run: There is no current event loop in thread 'asyncio_0'.
2024-10-23 16:21:02,177 - werkzeug - INFO - 127.0.0.1 - - [23/Oct/2024 16:21:02] "GET /graphrag/init HTTP/1.1" 200 -
2024-10-23 16:22:18,002 - werkzeug - INFO -  * Detected change in 'D:\\code\\grapgrag_flask\\main.py', reloading
2024-10-23 16:22:18,441 - werkzeug - INFO -  * Restarting with stat
2024-10-23 16:22:24,545 - werkzeug - WARNING -  * Debugger is active!
2024-10-23 16:22:24,546 - werkzeug - INFO -  * Debugger PIN: 683-701-297
2024-10-23 16:22:26,220 - root - INFO - YAML ÎÄ¼þÒÑÖØÐÂÐ´Èë³É¹¦£¡
2024-10-23 16:22:26,221 - root - INFO - .env file has been updated at: ./rag\.env
2024-10-23 16:22:26,230 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-23 16:22:26,237 - graphrag_api.index - INFO - Logging enabled at rag\output\20241023-162226\reports\indexing-engine.log
2024-10-23 16:22:26,239 - graphrag_api.index - INFO - Starting pipeline run for: 20241023-162226, self.dryrun=False
2024-10-23 16:22:26,239 - graphrag_api.index - INFO - Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "glm-4-flash",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "rag",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/openai/api/v2",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
2024-10-23 16:22:26,239 - root - ERROR - Error in indexer run: signal only works in main thread of the main interpreter
2024-10-23 16:22:26,240 - werkzeug - INFO - 127.0.0.1 - - [23/Oct/2024 16:22:26] "GET /graphrag/init HTTP/1.1" 200 -
2024-10-23 16:23:51,739 - werkzeug - INFO -  * Detected change in 'D:\\code\\grapgrag_flask\\main.py', reloading
2024-10-23 16:23:52,193 - werkzeug - INFO -  * Restarting with stat
2024-10-23 16:23:58,226 - werkzeug - WARNING -  * Debugger is active!
2024-10-23 16:23:58,227 - werkzeug - INFO -  * Debugger PIN: 683-701-297
2024-10-23 16:24:01,577 - werkzeug - INFO -  * Detected change in 'D:\\code\\grapgrag_flask\\main.py', reloading
2024-10-23 16:24:02,009 - werkzeug - INFO -  * Restarting with stat
2024-10-23 16:24:10,870 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-23 16:24:10,871 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-23 16:24:16,789 - root - INFO - YAML ÎÄ¼þÒÑÖØÐÂÐ´Èë³É¹¦£¡
2024-10-23 16:24:16,790 - root - INFO - .env file has been updated at: ./rag\.env
2024-10-23 16:24:16,801 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-23 16:24:16,804 - graphrag_api.index - INFO - Logging enabled at rag\output\20241023-162416\reports\indexing-engine.log
2024-10-23 16:24:16,807 - graphrag_api.index - INFO - Starting pipeline run for: 20241023-162416, self.dryrun=False
2024-10-23 16:24:16,808 - graphrag_api.index - INFO - Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "glm-4-flash",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "rag",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/openai/api/v2",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
2024-10-23 16:24:16,808 - root - ERROR - Error in indexer run: signal only works in main thread of the main interpreter
2024-10-23 16:24:16,808 - werkzeug - INFO - 127.0.0.1 - - [23/Oct/2024 16:24:16] "GET /graphrag/init HTTP/1.1" 200 -
2024-10-23 16:26:21,256 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-23 16:26:21,256 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-23 16:26:27,911 - root - INFO - YAML ÎÄ¼þÒÑÖØÐÂÐ´Èë³É¹¦£¡
2024-10-23 16:26:27,911 - root - INFO - .env file has been updated at: ./rag\.env
2024-10-23 16:31:04,304 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-23 16:31:04,304 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-23 16:31:09,521 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-23 16:31:09,524 - graphrag_api.index - INFO - Logging enabled at rag\output\20241023-163109\reports\indexing-engine.log
2024-10-23 16:31:09,527 - graphrag_api.index - INFO - Starting pipeline run for: 20241023-163109, self.dryrun=False
2024-10-23 16:31:09,528 - graphrag_api.index - INFO - Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "glm-4-flash",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "rag",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/openai/api/v2",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
2024-10-23 16:31:09,529 - graphrag.index.create_pipeline_config - INFO - skipping workflows 
2024-10-23 16:31:09,529 - graphrag.index.run - INFO - Running pipeline
2024-10-23 16:31:09,529 - graphrag.index.storage.file_pipeline_storage - INFO - Creating file storage at rag\output\20241023-163109\artifacts
2024-10-23 16:31:09,530 - graphrag.index.input.load_input - INFO - loading input from root_dir=input
2024-10-23 16:31:09,530 - graphrag.index.input.load_input - INFO - using file storage for input
2024-10-23 16:31:09,530 - graphrag.index.storage.file_pipeline_storage - INFO - search rag\input for files matching .*\.txt$
2024-10-23 16:31:09,530 - graphrag.index.input.text - INFO - found text files from input, found [('input.txt', {})]
2024-10-23 16:31:09,532 - graphrag.index.input.text - INFO - Found 1 files, loading 1
2024-10-23 16:31:09,533 - graphrag.index.workflows.load - INFO - Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
2024-10-23 16:31:09,533 - graphrag.index.run - INFO - Final # of rows loaded: 1
2024-10-23 16:31:09,617 - graphrag.index.run - INFO - Running workflow: create_base_text_units...
2024-10-23 16:31:09,618 - graphrag.index.run - INFO - dependencies for create_base_text_units: []
2024-10-23 16:31:09,618 - datashaper.workflow.workflow - INFO - executing verb orderby
2024-10-23 16:31:09,619 - datashaper.workflow.workflow - INFO - executing verb zip
2024-10-23 16:31:09,620 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-23 16:31:09,621 - datashaper.workflow.workflow - INFO - executing verb chunk
2024-10-23 16:31:09,750 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 16:31:09,751 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-23 16:31:09,753 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 16:31:09,753 - datashaper.workflow.workflow - INFO - executing verb genid
2024-10-23 16:31:09,754 - datashaper.workflow.workflow - INFO - executing verb unzip
2024-10-23 16:31:09,755 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-23 16:31:09,755 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 16:31:09,759 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_text_units.parquet
2024-10-23 16:31:09,852 - graphrag.index.run - INFO - Running workflow: create_base_extracted_entities...
2024-10-23 16:31:09,852 - graphrag.index.run - INFO - dependencies for create_base_extracted_entities: ['create_base_text_units']
2024-10-23 16:31:09,853 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-23 16:31:09,866 - datashaper.workflow.workflow - INFO - executing verb entity_extract
2024-10-23 16:31:09,869 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/zhipu/api/v2/chat/completions
2024-10-23 16:31:10,030 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for glm-4-flash: TPM=0, RPM=0
2024-10-23 16:31:10,030 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for glm-4-flash: 25
2024-10-23 16:31:29,190 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:29,195 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 19.125. input_tokens=2937, output_tokens=549
2024-10-23 16:31:31,459 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:31,462 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 21.390000000130385. input_tokens=2937, output_tokens=748
2024-10-23 16:31:32,772 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:32,777 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 22.734999999869615. input_tokens=2936, output_tokens=731
2024-10-23 16:31:32,779 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:32,782 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 22.734999999869615. input_tokens=2936, output_tokens=578
2024-10-23 16:31:33,409 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:33,410 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 23.344000000040978. input_tokens=2936, output_tokens=608
2024-10-23 16:31:35,353 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:35,354 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 25.29700000002049. input_tokens=2937, output_tokens=677
2024-10-23 16:31:35,812 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:35,816 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 25.75. input_tokens=2935, output_tokens=894
2024-10-23 16:31:37,976 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:37,977 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 27.905999999959022. input_tokens=2936, output_tokens=864
2024-10-23 16:31:38,309 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:38,310 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 28.25. input_tokens=2936, output_tokens=699
2024-10-23 16:31:38,346 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:38,347 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 28.265000000130385. input_tokens=2747, output_tokens=1031
2024-10-23 16:31:42,503 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:42,505 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 32.46899999980815. input_tokens=2934, output_tokens=830
2024-10-23 16:31:42,720 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:42,722 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 11.25. input_tokens=34, output_tokens=367
2024-10-23 16:31:45,239 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:45,243 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 35.20399999991059. input_tokens=2935, output_tokens=1043
2024-10-23 16:31:45,655 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:45,659 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 35.59400000004098. input_tokens=2937, output_tokens=1019
2024-10-23 16:31:46,622 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:46,626 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 17.42200000002049. input_tokens=34, output_tokens=412
2024-10-23 16:31:48,233 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:48,234 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 38.17200000002049. input_tokens=2937, output_tokens=1033
2024-10-23 16:31:48,300 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:48,303 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 14.890999999828637. input_tokens=34, output_tokens=491
2024-10-23 16:31:52,005 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:52,006 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 14.030999999959022. input_tokens=34, output_tokens=485
2024-10-23 16:31:53,118 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:53,121 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 10.610000000102445. input_tokens=34, output_tokens=372
2024-10-23 16:31:56,253 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:56,258 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 23.468999999808148. input_tokens=34, output_tokens=1035
2024-10-23 16:31:59,042 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:31:59,043 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 23.218000000109896. input_tokens=34, output_tokens=810
2024-10-23 16:32:01,024 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:32:01,025 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 25.67200000002049. input_tokens=34, output_tokens=1090
2024-10-23 16:32:06,050 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:32:06,056 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 33.26599999982864. input_tokens=34, output_tokens=1023
2024-10-23 16:32:07,802 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:32:07,803 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 29.45299999997951. input_tokens=34, output_tokens=1025
2024-10-23 16:32:09,377 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:32:09,380 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 31.07799999997951. input_tokens=34, output_tokens=1033
2024-10-23 16:32:44,863 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-23 16:32:44,863 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-23 16:32:50,348 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-23 16:32:50,352 - graphrag_api.index - INFO - Logging enabled at rag\output\20241023-163250\reports\indexing-engine.log
2024-10-23 16:32:50,355 - graphrag_api.index - INFO - Starting pipeline run for: 20241023-163250, self.dryrun=False
2024-10-23 16:32:50,355 - graphrag_api.index - INFO - Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "glm-4-flash",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "rag",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/openai/api/v2",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
2024-10-23 16:32:50,357 - graphrag.index.create_pipeline_config - INFO - skipping workflows 
2024-10-23 16:32:50,357 - graphrag.index.run - INFO - Running pipeline
2024-10-23 16:32:50,357 - graphrag.index.storage.file_pipeline_storage - INFO - Creating file storage at rag\output\20241023-163250\artifacts
2024-10-23 16:32:50,357 - graphrag.index.input.load_input - INFO - loading input from root_dir=input
2024-10-23 16:32:50,357 - graphrag.index.input.load_input - INFO - using file storage for input
2024-10-23 16:32:50,358 - graphrag.index.storage.file_pipeline_storage - INFO - search rag\input for files matching .*\.txt$
2024-10-23 16:32:50,358 - graphrag.index.input.text - INFO - found text files from input, found [('input.txt', {})]
2024-10-23 16:32:50,360 - graphrag.index.input.text - INFO - Found 1 files, loading 1
2024-10-23 16:32:50,361 - graphrag.index.workflows.load - INFO - Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
2024-10-23 16:32:50,361 - graphrag.index.run - INFO - Final # of rows loaded: 1
2024-10-23 16:32:50,459 - graphrag.index.run - INFO - Running workflow: create_base_text_units...
2024-10-23 16:32:50,459 - graphrag.index.run - INFO - dependencies for create_base_text_units: []
2024-10-23 16:32:50,460 - datashaper.workflow.workflow - INFO - executing verb orderby
2024-10-23 16:32:50,460 - datashaper.workflow.workflow - INFO - executing verb zip
2024-10-23 16:32:50,460 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-23 16:32:50,462 - datashaper.workflow.workflow - INFO - executing verb chunk
2024-10-23 16:32:50,585 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 16:32:50,585 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-23 16:32:50,586 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 16:32:50,587 - datashaper.workflow.workflow - INFO - executing verb genid
2024-10-23 16:32:50,587 - datashaper.workflow.workflow - INFO - executing verb unzip
2024-10-23 16:32:50,587 - datashaper.workflow.workflow - ERROR - Error executing verb "unzip" in create_base_text_units: Columns must be same length as key
Traceback (most recent call last):
  File "C:\Users\LH\.conda\envs\graphrag\lib\site-packages\datashaper\workflow\workflow.py", line 410, in _execute_verb
    result = node.verb.func(**verb_args)
  File "C:\Users\LH\.conda\envs\graphrag\lib\site-packages\graphrag\index\verbs\unzip.py", line 23, in unzip
    table[to] = pd.DataFrame(table[column].tolist(), index=table.index)
  File "C:\Users\LH\.conda\envs\graphrag\lib\site-packages\pandas\core\frame.py", line 4299, in __setitem__
    self._setitem_array(key, value)
  File "C:\Users\LH\.conda\envs\graphrag\lib\site-packages\pandas\core\frame.py", line 4341, in _setitem_array
    check_key_length(self.columns, key, value)
  File "C:\Users\LH\.conda\envs\graphrag\lib\site-packages\pandas\core\indexers\utils.py", line 390, in check_key_length
    raise ValueError("Columns must be same length as key")
ValueError: Columns must be same length as key
2024-10-23 16:32:50,590 - graphrag.index.reporting.file_workflow_callbacks - INFO - Error executing verb "unzip" in create_base_text_units: Columns must be same length as key details=None
2024-10-23 16:32:50,590 - graphrag.index.run - ERROR - error running workflow create_base_text_units
Traceback (most recent call last):
  File "C:\Users\LH\.conda\envs\graphrag\lib\site-packages\graphrag\index\run.py", line 325, in run_pipeline
    result = await workflow.run(context, callbacks)
  File "C:\Users\LH\.conda\envs\graphrag\lib\site-packages\datashaper\workflow\workflow.py", line 369, in run
    timing = await self._execute_verb(node, context, callbacks)
  File "C:\Users\LH\.conda\envs\graphrag\lib\site-packages\datashaper\workflow\workflow.py", line 410, in _execute_verb
    result = node.verb.func(**verb_args)
  File "C:\Users\LH\.conda\envs\graphrag\lib\site-packages\graphrag\index\verbs\unzip.py", line 23, in unzip
    table[to] = pd.DataFrame(table[column].tolist(), index=table.index)
  File "C:\Users\LH\.conda\envs\graphrag\lib\site-packages\pandas\core\frame.py", line 4299, in __setitem__
    self._setitem_array(key, value)
  File "C:\Users\LH\.conda\envs\graphrag\lib\site-packages\pandas\core\frame.py", line 4341, in _setitem_array
    check_key_length(self.columns, key, value)
  File "C:\Users\LH\.conda\envs\graphrag\lib\site-packages\pandas\core\indexers\utils.py", line 390, in check_key_length
    raise ValueError("Columns must be same length as key")
ValueError: Columns must be same length as key
2024-10-23 16:32:50,590 - graphrag.index.reporting.file_workflow_callbacks - INFO - Error running pipeline! details=None
2024-10-23 16:32:50,595 - graphrag_api.index - ERROR - Errors occurred during the pipeline run, see logs for more details.
2024-10-23 16:38:26,209 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-23 16:38:26,209 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-23 16:38:32,911 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-23 16:38:32,914 - graphrag_api.index - INFO - Logging enabled at rag\output\20241023-163832\reports\indexing-engine.log
2024-10-23 16:38:32,917 - graphrag_api.index - INFO - Starting pipeline run for: 20241023-163832, self.dryrun=False
2024-10-23 16:38:32,917 - graphrag_api.index - INFO - Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "glm-4-flash",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "rag",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/openai/api/v2",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
2024-10-23 16:38:32,919 - graphrag.index.create_pipeline_config - INFO - skipping workflows 
2024-10-23 16:38:32,919 - graphrag.index.run - INFO - Running pipeline
2024-10-23 16:38:32,920 - graphrag.index.storage.file_pipeline_storage - INFO - Creating file storage at rag\output\20241023-163832\artifacts
2024-10-23 16:38:32,920 - graphrag.index.input.load_input - INFO - loading input from root_dir=input
2024-10-23 16:38:32,920 - graphrag.index.input.load_input - INFO - using file storage for input
2024-10-23 16:38:32,920 - graphrag.index.storage.file_pipeline_storage - INFO - search rag\input for files matching .*\.txt$
2024-10-23 16:38:32,920 - graphrag.index.input.text - INFO - found text files from input, found [('input.txt', {})]
2024-10-23 16:38:32,925 - graphrag.index.input.text - INFO - Found 1 files, loading 1
2024-10-23 16:38:32,927 - graphrag.index.workflows.load - INFO - Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
2024-10-23 16:38:32,927 - graphrag.index.run - INFO - Final # of rows loaded: 1
2024-10-23 16:38:33,010 - graphrag.index.run - INFO - Running workflow: create_base_text_units...
2024-10-23 16:38:33,010 - graphrag.index.run - INFO - dependencies for create_base_text_units: []
2024-10-23 16:38:33,010 - datashaper.workflow.workflow - INFO - executing verb orderby
2024-10-23 16:38:33,011 - datashaper.workflow.workflow - INFO - executing verb zip
2024-10-23 16:38:33,011 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-23 16:38:33,013 - datashaper.workflow.workflow - INFO - executing verb chunk
2024-10-23 16:38:33,139 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 16:38:33,140 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-23 16:38:33,140 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 16:38:33,141 - datashaper.workflow.workflow - INFO - executing verb genid
2024-10-23 16:38:33,142 - datashaper.workflow.workflow - INFO - executing verb unzip
2024-10-23 16:38:33,143 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-23 16:38:33,143 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 16:38:33,147 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_text_units.parquet
2024-10-23 16:38:33,249 - graphrag.index.run - INFO - Running workflow: create_base_extracted_entities...
2024-10-23 16:38:33,250 - graphrag.index.run - INFO - dependencies for create_base_extracted_entities: ['create_base_text_units']
2024-10-23 16:38:33,250 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-23 16:38:33,267 - datashaper.workflow.workflow - INFO - executing verb entity_extract
2024-10-23 16:38:33,272 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/zhipu/api/v2/chat/completions
2024-10-23 16:38:33,439 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for glm-4-flash: TPM=0, RPM=0
2024-10-23 16:38:33,440 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for glm-4-flash: 25
2024-10-23 16:38:46,193 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:38:46,196 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 12.719000000040978. input_tokens=2937, output_tokens=748
2024-10-23 16:38:47,351 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:38:47,354 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 13.890999999828637. input_tokens=2937, output_tokens=654
2024-10-23 16:38:47,463 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:38:47,465 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 13.984000000171363. input_tokens=2937, output_tokens=549
2024-10-23 16:38:48,032 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:38:48,033 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 14.577999999979511. input_tokens=2936, output_tokens=731
2024-10-23 16:38:49,302 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:38:49,303 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 15.858999999938533. input_tokens=2936, output_tokens=578
2024-10-23 16:38:49,571 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:38:49,572 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 16.109999999869615. input_tokens=2936, output_tokens=697
2024-10-23 16:38:51,620 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:38:51,622 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 18.17200000002049. input_tokens=2934, output_tokens=815
2024-10-23 16:38:51,679 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:38:51,681 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 18.218999999808148. input_tokens=2936, output_tokens=698
2024-10-23 16:38:53,801 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:38:53,802 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 7.608999999938533. input_tokens=34, output_tokens=366
2024-10-23 16:38:54,791 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:38:54,792 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 21.32799999997951. input_tokens=2937, output_tokens=939
2024-10-23 16:38:55,223 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:38:55,224 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 21.75. input_tokens=2936, output_tokens=864
2024-10-23 16:38:56,187 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:38:56,188 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 22.718999999808148. input_tokens=2935, output_tokens=969
2024-10-23 16:38:59,330 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:38:59,331 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 11.859999999869615. input_tokens=34, output_tokens=412
2024-10-23 16:38:59,396 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:38:59,400 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 25.937999999849126. input_tokens=2937, output_tokens=1033
2024-10-23 16:39:02,490 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:02,491 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 29.016000000061467. input_tokens=2747, output_tokens=1031
2024-10-23 16:39:04,702 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:04,703 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "Process" with 0 retries took 31.234999999869615. input_tokens=2935, output_tokens=1023
2024-10-23 16:39:06,125 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:06,128 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 10.891000000061467. input_tokens=34, output_tokens=419
2024-10-23 16:39:11,244 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:11,246 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 19.625. input_tokens=34, output_tokens=785
2024-10-23 16:39:12,957 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:12,961 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 18.17200000002049. input_tokens=34, output_tokens=777
2024-10-23 16:39:13,690 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:13,692 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 25.67200000002049. input_tokens=34, output_tokens=1035
2024-10-23 16:39:13,911 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:13,913 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 26.562000000150874. input_tokens=34, output_tokens=1023
2024-10-23 16:39:16,608 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:16,610 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 27.29700000002049. input_tokens=34, output_tokens=1023
2024-10-23 16:39:17,051 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:17,053 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 27.483999999938533. input_tokens=34, output_tokens=1047
2024-10-23 16:39:19,447 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:19,448 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 27.766000000061467. input_tokens=34, output_tokens=1030
2024-10-23 16:39:23,878 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:23,883 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 24.483999999938533. input_tokens=34, output_tokens=963
2024-10-23 16:39:24,555 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:24,556 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 22.061999999918044. input_tokens=34, output_tokens=985
2024-10-23 16:39:25,664 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:25,668 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 29.484000000171363. input_tokens=34, output_tokens=987
2024-10-23 16:39:33,478 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:33,483 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "extract-continuation-0" with 0 retries took 28.780999999959022. input_tokens=34, output_tokens=1023
2024-10-23 16:39:33,492 - datashaper.workflow.workflow - INFO - executing verb merge_graphs
2024-10-23 16:39:33,523 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_extracted_entities.parquet
2024-10-23 16:39:33,703 - graphrag.index.run - INFO - Running workflow: create_summarized_entities...
2024-10-23 16:39:33,703 - graphrag.index.run - INFO - dependencies for create_summarized_entities: ['create_base_extracted_entities']
2024-10-23 16:39:33,704 - graphrag.index.run - INFO - read table from storage: create_base_extracted_entities.parquet
2024-10-23 16:39:33,713 - datashaper.workflow.workflow - INFO - executing verb summarize_descriptions
2024-10-23 16:39:36,117 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:36,117 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 2.25. input_tokens=150, output_tokens=43
2024-10-23 16:39:36,151 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:36,152 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 2.280999999959022. input_tokens=146, output_tokens=47
2024-10-23 16:39:36,191 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:36,193 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 2.327999999979511. input_tokens=149, output_tokens=49
2024-10-23 16:39:36,276 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:36,278 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 2.4379999998491257. input_tokens=146, output_tokens=66
2024-10-23 16:39:36,295 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:36,296 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 2.4370000001508743. input_tokens=146, output_tokens=43
2024-10-23 16:39:36,311 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:36,312 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 2.4689999998081475. input_tokens=146, output_tokens=61
2024-10-23 16:39:36,328 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:36,329 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 2.469000000040978. input_tokens=156, output_tokens=75
2024-10-23 16:39:36,576 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:36,577 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 2.6880000000819564. input_tokens=152, output_tokens=67
2024-10-23 16:39:36,657 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:36,660 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 2.8129999998491257. input_tokens=154, output_tokens=49
2024-10-23 16:39:36,668 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:36,670 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 2.796000000089407. input_tokens=149, output_tokens=48
2024-10-23 16:39:37,177 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:37,178 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 3.3439999998081475. input_tokens=175, output_tokens=114
2024-10-23 16:39:37,203 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:37,205 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 3.344000000040978. input_tokens=151, output_tokens=59
2024-10-23 16:39:37,253 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:37,254 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 3.375. input_tokens=150, output_tokens=79
2024-10-23 16:39:37,315 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:37,316 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 3.4839999999385327. input_tokens=192, output_tokens=106
2024-10-23 16:39:37,323 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:37,324 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 3.5160000000614673. input_tokens=270, output_tokens=134
2024-10-23 16:39:37,338 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:37,340 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 3.515000000130385. input_tokens=180, output_tokens=74
2024-10-23 16:39:37,379 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:37,383 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 3.530999999959022. input_tokens=156, output_tokens=72
2024-10-23 16:39:37,495 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:37,498 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 3.6410000000614673. input_tokens=146, output_tokens=69
2024-10-23 16:39:37,615 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:37,619 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 3.7350000001024455. input_tokens=165, output_tokens=84
2024-10-23 16:39:37,620 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:37,621 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 3.797000000020489. input_tokens=169, output_tokens=80
2024-10-23 16:39:37,767 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:37,770 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 3.9219999997876585. input_tokens=217, output_tokens=99
2024-10-23 16:39:37,830 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:37,839 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 1.5150000001303852. input_tokens=148, output_tokens=45
2024-10-23 16:39:37,849 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:37,851 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 3.969000000040978. input_tokens=185, output_tokens=82
2024-10-23 16:39:37,998 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:38,001 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 1.7190000000409782. input_tokens=152, output_tokens=51
2024-10-23 16:39:38,079 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:38,080 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 1.7660000000614673. input_tokens=162, output_tokens=41
2024-10-23 16:39:38,208 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:38,210 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 4.390000000130385. input_tokens=240, output_tokens=144
2024-10-23 16:39:38,239 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:38,240 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 1.672000000020489. input_tokens=146, output_tokens=37
2024-10-23 16:39:38,257 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:38,259 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 4.4219999997876585. input_tokens=177, output_tokens=93
2024-10-23 16:39:38,291 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:38,292 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 4.468000000109896. input_tokens=185, output_tokens=114
2024-10-23 16:39:38,447 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:38,449 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 2.327999999979511. input_tokens=156, output_tokens=81
2024-10-23 16:39:38,482 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:38,484 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 1.8129999998491257. input_tokens=151, output_tokens=48
2024-10-23 16:39:39,122 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:39,126 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 2.922000000020489. input_tokens=175, output_tokens=75
2024-10-23 16:39:39,396 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:39,398 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 3.25. input_tokens=150, output_tokens=101
2024-10-23 16:39:39,459 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:39,461 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 2.797000000020489. input_tokens=146, output_tokens=90
2024-10-23 16:39:39,573 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:39,574 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 3.281999999890104. input_tokens=160, output_tokens=72
2024-10-23 16:39:39,593 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_summarized_entities.parquet
2024-10-23 16:39:39,770 - graphrag.index.run - INFO - Running workflow: create_base_entity_graph...
2024-10-23 16:39:39,772 - graphrag.index.run - INFO - dependencies for create_base_entity_graph: ['create_summarized_entities']
2024-10-23 16:39:39,772 - graphrag.index.run - INFO - read table from storage: create_summarized_entities.parquet
2024-10-23 16:39:39,782 - datashaper.workflow.workflow - INFO - executing verb cluster_graph
2024-10-23 16:39:39,881 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 16:39:39,885 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_entity_graph.parquet
2024-10-23 16:39:40,068 - graphrag.index.run - INFO - Running workflow: create_final_entities...
2024-10-23 16:39:40,068 - graphrag.index.run - INFO - dependencies for create_final_entities: ['create_base_entity_graph']
2024-10-23 16:39:40,069 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-23 16:39:40,082 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-23 16:39:40,111 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 16:39:40,112 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 16:39:40,113 - datashaper.workflow.workflow - INFO - executing verb dedupe
2024-10-23 16:39:40,114 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 16:39:40,115 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 16:39:40,123 - datashaper.workflow.workflow - INFO - executing verb text_split
2024-10-23 16:39:40,131 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-23 16:39:40,133 - datashaper.workflow.workflow - INFO - executing verb merge
2024-10-23 16:39:40,201 - datashaper.workflow.workflow - INFO - executing verb text_embed
2024-10-23 16:39:40,203 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/openai/api/v2
2024-10-23 16:39:40,494 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
2024-10-23 16:39:40,495 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for text-embedding-3-small: 25
2024-10-23 16:39:40,512 - graphrag.index.verbs.text.embed.strategies.openai - INFO - embedding 286 inputs via 286 snippets using 18 batches. max_batch_size=16, max_tokens=8191
2024-10-23 16:39:41,656 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:41,705 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:41,769 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:41,823 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.297000000020489. input_tokens=555, output_tokens=0
2024-10-23 16:39:41,841 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:41,842 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:41,861 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.327999999979511. input_tokens=241, output_tokens=0
2024-10-23 16:39:41,877 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:41,889 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:41,915 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:41,917 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:41,929 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:41,950 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:41,975 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.4379999998491257. input_tokens=480, output_tokens=0
2024-10-23 16:39:41,997 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.4690000000409782. input_tokens=590, output_tokens=0
2024-10-23 16:39:42,020 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:42,052 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.5309999999590218. input_tokens=295, output_tokens=0
2024-10-23 16:39:42,069 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.547000000020489. input_tokens=461, output_tokens=0
2024-10-23 16:39:42,094 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.5620000001508743. input_tokens=291, output_tokens=0
2024-10-23 16:39:42,115 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.6100000001024455. input_tokens=310, output_tokens=0
2024-10-23 16:39:42,137 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.6089999999385327. input_tokens=763, output_tokens=0
2024-10-23 16:39:42,156 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.6410000000614673. input_tokens=647, output_tokens=0
2024-10-23 16:39:42,181 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.6559999999590218. input_tokens=403, output_tokens=0
2024-10-23 16:39:42,200 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:42,259 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.7339999999385327. input_tokens=400, output_tokens=0
2024-10-23 16:39:42,301 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:42,348 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:42,398 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.875. input_tokens=341, output_tokens=0
2024-10-23 16:39:42,514 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.9839999999385327. input_tokens=461, output_tokens=0
2024-10-23 16:39:42,555 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:42,565 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 2.030999999959022. input_tokens=439, output_tokens=0
2024-10-23 16:39:42,699 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 2.1880000000819564. input_tokens=718, output_tokens=0
2024-10-23 16:39:42,716 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:42,744 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:39:42,881 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 2.3589999999385327. input_tokens=459, output_tokens=0
2024-10-23 16:39:42,956 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 2.422000000020489. input_tokens=565, output_tokens=0
2024-10-23 16:39:42,978 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-23 16:39:42,978 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 16:39:42,987 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_entities.parquet
2024-10-23 16:39:43,193 - graphrag.index.run - INFO - Running workflow: create_final_nodes...
2024-10-23 16:39:43,194 - graphrag.index.run - INFO - dependencies for create_final_nodes: ['create_base_entity_graph']
2024-10-23 16:39:43,194 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-23 16:39:43,200 - datashaper.workflow.workflow - INFO - executing verb layout_graph
2024-10-23 16:39:43,316 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-23 16:39:43,350 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-23 16:39:43,383 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 16:39:43,394 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-23 16:39:43,395 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 16:39:43,396 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 16:39:43,396 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-23 16:39:43,399 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-23 16:39:43,405 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 16:39:43,408 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_nodes.parquet
2024-10-23 16:39:43,594 - graphrag.index.run - INFO - Running workflow: create_final_communities...
2024-10-23 16:39:43,594 - graphrag.index.run - INFO - dependencies for create_final_communities: ['create_base_entity_graph']
2024-10-23 16:39:43,594 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-23 16:39:43,599 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-23 16:39:43,626 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-23 16:39:43,655 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-23 16:39:43,658 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-23 16:39:43,667 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-23 16:39:43,675 - datashaper.workflow.workflow - INFO - executing verb concat
2024-10-23 16:39:43,676 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 16:39:43,710 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-23 16:39:43,716 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-23 16:39:43,722 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 16:39:43,726 - datashaper.workflow.workflow - INFO - executing verb fill
2024-10-23 16:39:43,727 - datashaper.workflow.workflow - INFO - executing verb merge
2024-10-23 16:39:43,734 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-23 16:39:43,735 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 16:39:43,737 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_communities.parquet
2024-10-23 16:39:43,940 - graphrag.index.run - INFO - Running workflow: join_text_units_to_entity_ids...
2024-10-23 16:39:43,940 - graphrag.index.run - INFO - dependencies for join_text_units_to_entity_ids: ['create_final_entities']
2024-10-23 16:39:43,940 - graphrag.index.run - INFO - read table from storage: create_final_entities.parquet
2024-10-23 16:39:43,971 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 16:39:43,972 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-23 16:39:43,974 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-23 16:39:43,979 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table join_text_units_to_entity_ids.parquet
2024-10-23 16:39:44,157 - graphrag.index.run - INFO - Running workflow: create_final_relationships...
2024-10-23 16:39:44,158 - graphrag.index.run - INFO - dependencies for create_final_relationships: ['create_final_nodes', 'create_base_entity_graph']
2024-10-23 16:39:44,159 - graphrag.index.run - INFO - read table from storage: create_final_nodes.parquet
2024-10-23 16:39:44,173 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-23 16:39:44,176 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-23 16:39:44,202 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 16:39:44,213 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 16:39:44,214 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 16:39:44,221 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-23 16:39:44,222 - datashaper.workflow.workflow - INFO - executing verb compute_edge_combined_degree
2024-10-23 16:39:44,227 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-23 16:39:44,228 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-23 16:39:44,230 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_relationships.parquet
2024-10-23 16:39:44,430 - graphrag.index.run - INFO - Running workflow: join_text_units_to_relationship_ids...
2024-10-23 16:39:44,431 - graphrag.index.run - INFO - dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
2024-10-23 16:39:44,432 - graphrag.index.run - INFO - read table from storage: create_final_relationships.parquet
2024-10-23 16:39:44,440 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 16:39:44,441 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-23 16:39:44,443 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-23 16:39:44,445 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 16:39:44,448 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table join_text_units_to_relationship_ids.parquet
2024-10-23 16:39:44,627 - graphrag.index.run - INFO - Running workflow: create_final_community_reports...
2024-10-23 16:39:44,628 - graphrag.index.run - INFO - dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships']
2024-10-23 16:39:44,629 - graphrag.index.run - INFO - read table from storage: create_final_nodes.parquet
2024-10-23 16:39:44,635 - graphrag.index.run - INFO - read table from storage: create_final_relationships.parquet
2024-10-23 16:39:44,639 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports_nodes
2024-10-23 16:39:44,652 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports_edges
2024-10-23 16:39:44,656 - datashaper.workflow.workflow - INFO - executing verb restore_community_hierarchy
2024-10-23 16:39:44,663 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports
2024-10-23 16:39:44,663 - graphrag.index.verbs.graph.report.prepare_community_reports - INFO - Number of nodes at level=1 => 286
2024-10-23 16:39:44,739 - graphrag.index.verbs.graph.report.prepare_community_reports - INFO - Number of nodes at level=0 => 286
2024-10-23 16:39:44,803 - datashaper.workflow.workflow - INFO - executing verb create_community_reports
2024-10-23 16:39:59,304 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:59,306 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:39:59,308 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 14.405999999959022. input_tokens=2123, output_tokens=639
2024-10-23 16:39:59,914 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:39:59,918 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:39:59,922 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 15.077999999979511. input_tokens=2159, output_tokens=656
2024-10-23 16:40:00,921 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:00,922 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:00,923 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 16.093000000109896. input_tokens=2506, output_tokens=685
2024-10-23 16:40:01,717 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:01,721 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:01,723 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 16.859000000171363. input_tokens=3247, output_tokens=661
2024-10-23 16:40:03,040 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:03,045 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:03,048 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 18.171000000089407. input_tokens=2071, output_tokens=669
2024-10-23 16:40:03,125 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:03,126 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:03,126 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 18.25. input_tokens=2760, output_tokens=777
2024-10-23 16:40:03,955 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:03,958 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:03,960 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 19.04700000002049. input_tokens=2348, output_tokens=670
2024-10-23 16:40:04,470 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:04,475 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:04,475 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 19.594000000040978. input_tokens=2084, output_tokens=666
2024-10-23 16:40:04,698 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:04,702 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:04,704 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 19.859999999869615. input_tokens=2007, output_tokens=702
2024-10-23 16:40:05,294 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:05,297 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:05,300 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 20.468000000109896. input_tokens=3762, output_tokens=728
2024-10-23 16:40:05,900 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:05,904 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:05,906 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 21.016000000061467. input_tokens=2591, output_tokens=687
2024-10-23 16:40:07,240 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:07,244 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:07,245 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 22.344000000040978. input_tokens=2303, output_tokens=725
2024-10-23 16:40:07,246 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:07,247 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:07,248 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 22.328999999910593. input_tokens=2522, output_tokens=765
2024-10-23 16:40:07,623 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:07,626 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:07,628 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 22.703999999910593. input_tokens=2162, output_tokens=666
2024-10-23 16:40:08,264 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:08,266 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:08,266 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 23.405999999959022. input_tokens=2063, output_tokens=681
2024-10-23 16:40:23,719 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:23,720 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:23,722 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 15.422000000020489. input_tokens=2470, output_tokens=675
2024-10-23 16:40:23,889 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:23,890 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:23,891 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 15.593999999808148. input_tokens=2227, output_tokens=644
2024-10-23 16:40:24,594 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:24,595 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:24,596 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 16.265000000130385. input_tokens=2250, output_tokens=713
2024-10-23 16:40:25,476 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:25,477 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:25,477 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 17.20299999997951. input_tokens=4407, output_tokens=694
2024-10-23 16:40:25,965 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:25,967 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:25,969 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 17.640000000130385. input_tokens=2509, output_tokens=629
2024-10-23 16:40:26,088 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:26,089 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:26,090 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 17.781000000191852. input_tokens=2129, output_tokens=667
2024-10-23 16:40:28,282 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:28,283 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:28,283 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 19.969000000040978. input_tokens=2172, output_tokens=681
2024-10-23 16:40:28,296 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:28,297 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:28,297 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 19.968000000109896. input_tokens=2596, output_tokens=706
2024-10-23 16:40:28,653 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:28,654 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:28,655 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 20.312999999849126. input_tokens=3089, output_tokens=720
2024-10-23 16:40:29,760 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:29,761 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:29,763 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 21.45299999997951. input_tokens=2518, output_tokens=686
2024-10-23 16:40:33,297 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:40:33,298 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 16:40:33,300 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 25.0. input_tokens=4489, output_tokens=980
2024-10-23 16:40:33,303 - datashaper.workflow.workflow - INFO - executing verb window
2024-10-23 16:40:33,306 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_community_reports.parquet
2024-10-23 16:40:33,521 - graphrag.index.run - INFO - Running workflow: create_final_text_units...
2024-10-23 16:40:33,522 - graphrag.index.run - INFO - dependencies for create_final_text_units: ['join_text_units_to_relationship_ids', 'join_text_units_to_entity_ids', 'create_base_text_units']
2024-10-23 16:40:33,522 - graphrag.index.run - INFO - read table from storage: join_text_units_to_relationship_ids.parquet
2024-10-23 16:40:33,543 - graphrag.index.run - INFO - read table from storage: join_text_units_to_entity_ids.parquet
2024-10-23 16:40:33,563 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-23 16:40:33,568 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 16:40:33,569 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 16:40:33,569 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-23 16:40:33,574 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-23 16:40:33,580 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-23 16:40:33,584 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 16:40:33,587 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_text_units.parquet
2024-10-23 16:40:33,775 - graphrag.index.run - INFO - Running workflow: create_base_documents...
2024-10-23 16:40:33,776 - graphrag.index.run - INFO - dependencies for create_base_documents: ['create_final_text_units']
2024-10-23 16:40:33,776 - graphrag.index.run - INFO - read table from storage: create_final_text_units.parquet
2024-10-23 16:40:33,787 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-23 16:40:33,789 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 16:40:33,790 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 16:40:33,790 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-23 16:40:33,795 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-23 16:40:33,797 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-23 16:40:33,803 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 16:40:33,804 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-23 16:40:33,806 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_documents.parquet
2024-10-23 16:40:33,981 - graphrag.index.run - INFO - Running workflow: create_final_documents...
2024-10-23 16:40:33,981 - graphrag.index.run - INFO - dependencies for create_final_documents: ['create_base_documents']
2024-10-23 16:40:33,982 - graphrag.index.run - INFO - read table from storage: create_base_documents.parquet
2024-10-23 16:40:33,990 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 16:40:33,992 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_documents.parquet
2024-10-23 16:40:34,021 - graphrag_api.index - INFO - All workflows completed successfully.
2024-10-23 16:41:28,833 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-23 16:41:30,712 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-23 16:41:33,756 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:41:33,906 - graphrag.query.structured_search.local_search.search - INFO - GENERATE ANSWER: 1729672891.4142482. QUERY: ÔõÃ´ÊµÏÖÒ»¸öragÏµÍ³
2024-10-23 16:41:38,073 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:41:41,812 - werkzeug - INFO - 127.0.0.1 - - [23/Oct/2024 16:41:41] "POST /graphrag/chat HTTP/1.1" 200 -
2024-10-23 16:43:53,750 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-23 16:43:53,750 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-23 16:44:10,378 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-23 16:44:11,458 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-23 16:44:12,869 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 16:44:12,910 - graphrag.query.structured_search.local_search.search - INFO - GENERATE ANSWER: 1729673051.8755004. QUERY: ÔõÃ´ÊµÏÖÒ»¸öragÏµÍ³
2024-10-23 16:44:17,187 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:44:20,866 - werkzeug - INFO - 127.0.0.1 - - [23/Oct/2024 16:44:20] "POST /graphrag/chat HTTP/1.1" 200 -
2024-10-23 16:44:29,938 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-23 16:44:31,204 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-23 16:44:31,845 - graphrag.query.context_builder.community_context - INFO - Computing community weights...
2024-10-23 16:44:42,772 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:44:42,774 - graphrag.query.structured_search.global_search.search - INFO - Map response: {
    "points": [
        {"description": "RAG£¨Retrieval-Augmented Generation£©ÏµÍ³ÊÇÒ»ÖÖ½áºÏÁË¼ìË÷ºÍÉú³É¼¼ÊõµÄ×ÔÈ»ÓïÑÔ´¦ÀíÏµÍ³¡£ÒªÊµÏÖÒ»¸öRAGÏµÍ³£¬Ê×ÏÈÐèÒª¹¹½¨Ò»¸ö¼ìË÷ÏµÍ³À´´Ó´óÁ¿Êý¾ÝÖÐ¼ìË÷Ïà¹ØÐÅÏ¢£¬È»ºóÊ¹ÓÃÕâÐ©ÐÅÏ¢À´Éú³É»Ø´ð¡£ÒÔÏÂÊÇÊµÏÖRAGÏµÍ³µÄ¹Ø¼ü²½Öè£º", "score": 100},
        {"description": "1. Êý¾Ý×¼±¸£ºÊÕ¼¯ºÍÕûÀí´óÁ¿Ïà¹ØÊý¾Ý£¬ÕâÐ©Êý¾Ý½«ÓÃÓÚ¼ìË÷ºÍÉú³É»Ø´ð¡£Êý¾Ý¿ÉÒÔÊÇÎÄ±¾¡¢ÎÄµµ¡¢ÍøÒ³µÈ¡£[Data: Reports (11)]", "score": 90},
        {"description": "2. ¼ìË÷ÏµÍ³¹¹½¨£ºÊ¹ÓÃÐÅÏ¢¼ìË÷¼¼Êõ£¬ÈçËÑË÷ÒýÇæ»òÏòÁ¿Êý¾Ý¿â£¬´ÓÊý¾Ý¼¯ÖÐ¼ìË÷ÓëÓÃ»§²éÑ¯×îÏà¹ØµÄÐÅÏ¢¡£[Data: Reports (11)]", "score": 90},
        {"description": "3. Éú³ÉÄ£ÐÍÑµÁ·£ºÊ¹ÓÃ×ÔÈ»ÓïÑÔÉú³É¼¼Êõ£¬ÈçÐòÁÐµ½ÐòÁÐÄ£ÐÍ»ò»ùÓÚ×ª»»Æ÷µÄÄ£ÐÍ£¬ÑµÁ·Ò»¸öÉú³ÉÄ£ÐÍ£¬Ê¹ÆäÄÜ¹»¸ù¾Ý¼ìË÷µ½µÄÐÅÏ¢Éú³É»Ø´ð¡£[Data: Reports (11)]", "score": 90},
        {"description": "4. ÏµÍ³¼¯³É£º½«¼ìË÷ÏµÍ³ºÍÉú³ÉÄ£ÐÍ¼¯³Éµ½Ò»¸öÏµÍ³ÖÐ£¬ÒÔ±ãÔÚÓÃ»§²éÑ¯Ê±£¬ÏµÍ³ÄÜ¹»¼ìË÷Ïà¹ØÐÅÏ¢²¢Éú³É»Ø´ð¡£[Data: Reports (11)]", "score": 90},
        {"description": "5. ÏµÍ³ÓÅ»¯£º¸ù¾ÝÊµ¼ÊÓ¦ÓÃ³¡¾°ºÍÓÃ»§·´À¡£¬²»¶ÏÓÅ»¯¼ìË÷ºÍÉú³ÉÄ£ÐÍ£¬Ìá¸ßÏµÍ³µÄ×¼È·ÐÔºÍÐ§ÂÊ¡£[Data: Reports (11)]", "score": 80}
    ]
}
2024-10-23 16:44:44,614 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:44:44,616 - graphrag.query.structured_search.global_search.search - INFO - Map response: {
    "points": [
        {"description": "RAG£¨Read-Ask-Go£©ÏµÍ³ÊÇÒ»ÖÖ»ùÓÚÎÊ´ðµÄ¶Ô»°ÏµÍ³£¬ËüÍ¨¹ý¶ÁÈ¡ÐÅÏ¢¡¢Ñ¯ÎÊÓÃ»§ºÍÒýµ¼ÓÃ»§½øÐÐÏÂÒ»²½²Ù×÷À´Ìá¹©°ïÖú¡£ÊµÏÖÒ»¸öRAGÏµÍ³Í¨³£°üÀ¨ÒÔÏÂ²½Öè£º", "score": 100},
        {"description": "1. Êý¾Ý×¼±¸£ºÊÕ¼¯ºÍÕûÀíÏà¹ØÁìÓòµÄÖªÊ¶¿â£¬°üÀ¨ÎÄ±¾¡¢ÎÄµµ¡¢Êý¾Ý¿âµÈ¡£ÕâÐ©Êý¾Ý½«×÷ÎªRAGÏµÍ³µÄÖªÊ¶À´Ô´¡£[Data: Reports (15, 13, 25, 8, 20, 18, 24, 5, 23, 12, 22, 7, 19, 10, 17, 21, 3, 16)]", "score": 90},
        {"description": "2. ÖªÊ¶Í¼Æ×¹¹½¨£º½«ÊÕ¼¯µ½µÄÖªÊ¶¿â×ª»»ÎªÖªÊ¶Í¼Æ×£¬ÒÔ±ãÏµÍ³ÄÜ¹»¸üºÃµØÀí½âºÍ´¦ÀíÐÅÏ¢¡£[Data: Reports (15, 13, 25, 8, 20, 18, 24, 5, 23, 12, 22, 7, 19, 10, 17, 21, 3, 16)]", "score": 80},
        {"description": "3. ÎÊ´ðÏµÍ³Éè¼Æ£ºÉè¼ÆÎÊ´ðÏµÍ³µÄ¼Ü¹¹£¬°üÀ¨×ÔÈ»ÓïÑÔ´¦Àí£¨NLP£©Ä£¿é¡¢ÖªÊ¶¼ìË÷Ä£¿é¡¢¶Ô»°¹ÜÀíÄ£¿éµÈ¡£[Data: Reports (15, 13, 25, 8, 20, 18, 24, 5, 23, 12, 22, 7, 19, 10, 17, 21, 3, 16)]", "score": 70},
        {"description": "4. NLPÄ£¿éÊµÏÖ£ºÊµÏÖ×ÔÈ»ÓïÑÔ´¦ÀíÄ£¿é£¬°üÀ¨·Ö´Ê¡¢´ÊÐÔ±ê×¢¡¢ÃüÃûÊµÌåÊ¶±ð¡¢ÓïÒåÀí½âµÈ¡£[Data: Reports (15, 13, 25, 8, 20, 18, 24, 5, 23, 12, 22, 7, 19, 10, 17, 21, 3, 16)]", "score": 60},
        {"description": "5. ÖªÊ¶¼ìË÷Ä£¿éÊµÏÖ£ºÊµÏÖÖªÊ¶¼ìË÷Ä£¿é£¬¸ù¾ÝÓÃ»§µÄÎÊÌâ´ÓÖªÊ¶Í¼Æ×ÖÐ¼ìË÷Ïà¹ØÐÅÏ¢¡£[Data: Reports (15, 13, 25, 8, 20, 18, 24, 5, 23, 12, 22, 7, 19, 10, 17, 21, 3, 16)]", "score": 50},
        {"description": "6. ¶Ô»°¹ÜÀíÄ£¿éÊµÏÖ£ºÊµÏÖ¶Ô»°¹ÜÀíÄ£¿é£¬¸ºÔð¿ØÖÆ¶Ô»°Á÷³Ì£¬°üÀ¨Àí½âÓÃ»§ÒâÍ¼¡¢Éú³É»Ø´ð¡¢Òýµ¼ÓÃ»§µÈ¡£[Data: Reports (15, 13, 25, 8, 20, 18, 24, 5, 23, 12, 22, 7, 19, 10, 17, 21, 3, 16)]", "score": 40},
        {"description": "7. ÏµÍ³²âÊÔÓëÓÅ»¯£º¶ÔRAGÏµÍ³½øÐÐ²âÊÔ£¬ÆÀ¹ÀÆäÐÔÄÜºÍ×¼È·ÐÔ£¬²¢¸ù¾Ý²âÊÔ½á¹û½øÐÐÓÅ»¯¡£[Data: Reports (15, 13, 25, 8, 20, 18, 24, 5, 23, 12, 22, 7, 19, 10, 17, 21, 3, 16)]", "score": 30},
        {"description": "8. ÏµÍ³²¿ÊðÓëÎ¬»¤£º½«RAGÏµÍ³²¿Êðµ½Êµ¼Ê»·¾³ÖÐ£¬²¢½øÐÐÈÕ³£Î¬»¤ºÍ¸üÐÂ¡£[Data: Reports (15, 13, 25, 8, 20, 18, 24, 5, 23, 12, 22, 7, 19, 10, 17, 21, 3, 16)]", "score": 20}
    ]
}
2024-10-23 16:44:47,697 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 16:44:57,603 - werkzeug - INFO - 127.0.0.1 - - [23/Oct/2024 16:44:57] "POST /graphrag/chat HTTP/1.1" 200 -
2024-10-23 16:49:40,086 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-23 16:49:40,086 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-23 17:03:14,722 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-23 17:03:14,722 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-23 17:13:21,796 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-23 17:13:21,799 - graphrag_api.index - INFO - Logging enabled at rag\output\20241023-171321\reports\indexing-engine.log
2024-10-23 17:13:21,802 - graphrag_api.index - INFO - Starting pipeline run for: 20241023-171321, self.dryrun=False
2024-10-23 17:13:21,803 - graphrag_api.index - INFO - Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "glm-4-flash",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "rag",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/openai/api/v2",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
2024-10-23 17:13:21,804 - graphrag.index.create_pipeline_config - INFO - skipping workflows 
2024-10-23 17:13:21,804 - graphrag.index.run - INFO - Running pipeline
2024-10-23 17:13:21,804 - graphrag.index.storage.file_pipeline_storage - INFO - Creating file storage at rag\output\20241023-171321\artifacts
2024-10-23 17:13:21,804 - graphrag.index.input.load_input - INFO - loading input from root_dir=input
2024-10-23 17:13:21,804 - graphrag.index.input.load_input - INFO - using file storage for input
2024-10-23 17:13:21,805 - graphrag.index.storage.file_pipeline_storage - INFO - search rag\input for files matching .*\.txt$
2024-10-23 17:13:21,805 - graphrag.index.input.text - INFO - found text files from input, found [('input.txt', {})]
2024-10-23 17:13:21,811 - graphrag.index.input.text - INFO - Found 1 files, loading 1
2024-10-23 17:13:21,813 - graphrag.index.workflows.load - INFO - Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
2024-10-23 17:13:21,813 - graphrag.index.run - INFO - Final # of rows loaded: 1
2024-10-23 17:13:21,906 - graphrag.index.run - INFO - Running workflow: create_base_text_units...
2024-10-23 17:13:21,906 - graphrag.index.run - INFO - dependencies for create_base_text_units: []
2024-10-23 17:13:21,907 - datashaper.workflow.workflow - INFO - executing verb orderby
2024-10-23 17:13:21,907 - datashaper.workflow.workflow - INFO - executing verb zip
2024-10-23 17:13:21,908 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-23 17:13:21,910 - datashaper.workflow.workflow - INFO - executing verb chunk
2024-10-23 17:13:22,033 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 17:13:22,033 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-23 17:13:22,035 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 17:13:22,035 - datashaper.workflow.workflow - INFO - executing verb genid
2024-10-23 17:13:22,036 - datashaper.workflow.workflow - INFO - executing verb unzip
2024-10-23 17:13:22,037 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-23 17:13:22,037 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 17:13:22,041 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_text_units.parquet
2024-10-23 17:13:22,135 - graphrag.index.run - INFO - Running workflow: create_base_extracted_entities...
2024-10-23 17:13:22,136 - graphrag.index.run - INFO - dependencies for create_base_extracted_entities: ['create_base_text_units']
2024-10-23 17:13:22,136 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-23 17:13:22,151 - datashaper.workflow.workflow - INFO - executing verb entity_extract
2024-10-23 17:13:22,154 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/zhipu/api/v2/chat/completions
2024-10-23 17:13:22,310 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for glm-4-flash: TPM=0, RPM=0
2024-10-23 17:13:22,310 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for glm-4-flash: 25
2024-10-23 17:13:22,345 - datashaper.workflow.workflow - INFO - executing verb merge_graphs
2024-10-23 17:13:22,362 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_extracted_entities.parquet
2024-10-23 17:13:22,450 - graphrag.index.run - INFO - Running workflow: create_summarized_entities...
2024-10-23 17:13:22,451 - graphrag.index.run - INFO - dependencies for create_summarized_entities: ['create_base_extracted_entities']
2024-10-23 17:13:22,452 - graphrag.index.run - INFO - read table from storage: create_base_extracted_entities.parquet
2024-10-23 17:13:22,457 - datashaper.workflow.workflow - INFO - executing verb summarize_descriptions
2024-10-23 17:13:25,083 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 17:13:25,089 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 2.5780000002123415. input_tokens=162, output_tokens=41
2024-10-23 17:13:26,618 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 17:13:26,619 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 4.1100000001024455. input_tokens=165, output_tokens=85
2024-10-23 17:13:26,630 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_summarized_entities.parquet
2024-10-23 17:13:26,722 - graphrag.index.run - INFO - Running workflow: create_base_entity_graph...
2024-10-23 17:13:26,723 - graphrag.index.run - INFO - dependencies for create_base_entity_graph: ['create_summarized_entities']
2024-10-23 17:13:26,724 - graphrag.index.run - INFO - read table from storage: create_summarized_entities.parquet
2024-10-23 17:13:26,731 - datashaper.workflow.workflow - INFO - executing verb cluster_graph
2024-10-23 17:13:26,784 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 17:13:26,785 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_entity_graph.parquet
2024-10-23 17:13:26,885 - graphrag.index.run - INFO - Running workflow: create_final_entities...
2024-10-23 17:13:26,886 - graphrag.index.run - INFO - dependencies for create_final_entities: ['create_base_entity_graph']
2024-10-23 17:13:26,886 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-23 17:13:26,894 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-23 17:13:26,909 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 17:13:26,909 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 17:13:26,910 - datashaper.workflow.workflow - INFO - executing verb dedupe
2024-10-23 17:13:26,910 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 17:13:26,911 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 17:13:26,915 - datashaper.workflow.workflow - INFO - executing verb text_split
2024-10-23 17:13:26,918 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-23 17:13:26,918 - datashaper.workflow.workflow - INFO - executing verb merge
2024-10-23 17:13:26,947 - datashaper.workflow.workflow - INFO - executing verb text_embed
2024-10-23 17:13:26,948 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/openai/api/v2
2024-10-23 17:13:27,104 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
2024-10-23 17:13:27,104 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for text-embedding-3-small: 25
2024-10-23 17:13:27,115 - graphrag.index.verbs.text.embed.strategies.openai - INFO - embedding 286 inputs via 286 snippets using 18 batches. max_batch_size=16, max_tokens=8191
2024-10-23 17:13:28,427 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 17:13:28,477 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 17:13:28,551 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-23 17:13:28,582 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.452999999979511. input_tokens=462, output_tokens=0
2024-10-23 17:13:28,643 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.5149999998975545. input_tokens=555, output_tokens=0
2024-10-23 17:13:28,707 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.577999999979511. input_tokens=242, output_tokens=0
2024-10-23 17:13:28,720 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-23 17:13:28,720 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 17:13:28,726 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_entities.parquet
2024-10-23 17:13:28,864 - graphrag.index.run - INFO - Running workflow: create_final_nodes...
2024-10-23 17:13:28,864 - graphrag.index.run - INFO - dependencies for create_final_nodes: ['create_base_entity_graph']
2024-10-23 17:13:28,864 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-23 17:13:28,867 - datashaper.workflow.workflow - INFO - executing verb layout_graph
2024-10-23 17:13:28,934 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-23 17:13:28,953 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-23 17:13:28,970 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-23 17:13:28,971 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 17:13:28,978 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 17:13:28,978 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 17:13:28,978 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-23 17:13:28,980 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-23 17:13:28,985 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 17:13:28,987 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_nodes.parquet
2024-10-23 17:13:29,083 - graphrag.index.run - INFO - Running workflow: create_final_communities...
2024-10-23 17:13:29,084 - graphrag.index.run - INFO - dependencies for create_final_communities: ['create_base_entity_graph']
2024-10-23 17:13:29,084 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-23 17:13:29,087 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-23 17:13:29,102 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-23 17:13:29,116 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-23 17:13:29,118 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-23 17:13:29,123 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-23 17:13:29,126 - datashaper.workflow.workflow - INFO - executing verb concat
2024-10-23 17:13:29,127 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 17:13:29,144 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-23 17:13:29,147 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-23 17:13:29,151 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 17:13:29,153 - datashaper.workflow.workflow - INFO - executing verb fill
2024-10-23 17:13:29,154 - datashaper.workflow.workflow - INFO - executing verb merge
2024-10-23 17:13:29,157 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-23 17:13:29,157 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 17:13:29,159 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_communities.parquet
2024-10-23 17:13:29,269 - graphrag.index.run - INFO - Running workflow: join_text_units_to_entity_ids...
2024-10-23 17:13:29,270 - graphrag.index.run - INFO - dependencies for join_text_units_to_entity_ids: ['create_final_entities']
2024-10-23 17:13:29,270 - graphrag.index.run - INFO - read table from storage: create_final_entities.parquet
2024-10-23 17:13:29,289 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 17:13:29,289 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-23 17:13:29,291 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-23 17:13:29,293 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table join_text_units_to_entity_ids.parquet
2024-10-23 17:13:29,388 - graphrag.index.run - INFO - Running workflow: create_final_relationships...
2024-10-23 17:13:29,388 - graphrag.index.run - INFO - dependencies for create_final_relationships: ['create_base_entity_graph', 'create_final_nodes']
2024-10-23 17:13:29,389 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-23 17:13:29,392 - graphrag.index.run - INFO - read table from storage: create_final_nodes.parquet
2024-10-23 17:13:29,402 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-23 17:13:29,418 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 17:13:29,425 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 17:13:29,426 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-23 17:13:29,430 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-23 17:13:29,431 - datashaper.workflow.workflow - INFO - executing verb compute_edge_combined_degree
2024-10-23 17:13:29,434 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-23 17:13:29,435 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-23 17:13:29,437 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_relationships.parquet
2024-10-23 17:13:29,533 - graphrag.index.run - INFO - Running workflow: join_text_units_to_relationship_ids...
2024-10-23 17:13:29,533 - graphrag.index.run - INFO - dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
2024-10-23 17:13:29,533 - graphrag.index.run - INFO - read table from storage: create_final_relationships.parquet
2024-10-23 17:13:29,541 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 17:13:29,541 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-23 17:13:29,542 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-23 17:13:29,544 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 17:13:29,546 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table join_text_units_to_relationship_ids.parquet
2024-10-23 17:13:29,642 - graphrag.index.run - INFO - Running workflow: create_final_community_reports...
2024-10-23 17:13:29,642 - graphrag.index.run - INFO - dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships']
2024-10-23 17:13:29,642 - graphrag.index.run - INFO - read table from storage: create_final_nodes.parquet
2024-10-23 17:13:29,646 - graphrag.index.run - INFO - read table from storage: create_final_relationships.parquet
2024-10-23 17:13:29,649 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports_nodes
2024-10-23 17:13:29,656 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports_edges
2024-10-23 17:13:29,659 - datashaper.workflow.workflow - INFO - executing verb restore_community_hierarchy
2024-10-23 17:13:29,662 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports
2024-10-23 17:13:29,662 - graphrag.index.verbs.graph.report.prepare_community_reports - INFO - Number of nodes at level=1 => 286
2024-10-23 17:13:29,700 - graphrag.index.verbs.graph.report.prepare_community_reports - INFO - Number of nodes at level=0 => 286
2024-10-23 17:13:29,735 - datashaper.workflow.workflow - INFO - executing verb create_community_reports
2024-10-23 17:13:50,882 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-23 17:13:50,886 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-23 17:13:50,888 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 21.139999999897555. input_tokens=2173, output_tokens=697
2024-10-23 17:13:50,891 - datashaper.workflow.workflow - INFO - executing verb window
2024-10-23 17:13:50,894 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_community_reports.parquet
2024-10-23 17:13:51,003 - graphrag.index.run - INFO - Running workflow: create_final_text_units...
2024-10-23 17:13:51,003 - graphrag.index.run - INFO - dependencies for create_final_text_units: ['join_text_units_to_entity_ids', 'join_text_units_to_relationship_ids', 'create_base_text_units']
2024-10-23 17:13:51,004 - graphrag.index.run - INFO - read table from storage: join_text_units_to_entity_ids.parquet
2024-10-23 17:13:51,016 - graphrag.index.run - INFO - read table from storage: join_text_units_to_relationship_ids.parquet
2024-10-23 17:13:51,023 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-23 17:13:51,025 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 17:13:51,026 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 17:13:51,026 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-23 17:13:51,030 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-23 17:13:51,034 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-23 17:13:51,036 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 17:13:51,037 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_text_units.parquet
2024-10-23 17:13:51,137 - graphrag.index.run - INFO - Running workflow: create_base_documents...
2024-10-23 17:13:51,137 - graphrag.index.run - INFO - dependencies for create_base_documents: ['create_final_text_units']
2024-10-23 17:13:51,137 - graphrag.index.run - INFO - read table from storage: create_final_text_units.parquet
2024-10-23 17:13:51,148 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-23 17:13:51,149 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-23 17:13:51,150 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 17:13:51,150 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-23 17:13:51,154 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-23 17:13:51,156 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-23 17:13:51,159 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 17:13:51,159 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-23 17:13:51,161 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_documents.parquet
2024-10-23 17:13:51,254 - graphrag.index.run - INFO - Running workflow: create_final_documents...
2024-10-23 17:13:51,254 - graphrag.index.run - INFO - dependencies for create_final_documents: ['create_base_documents']
2024-10-23 17:13:51,254 - graphrag.index.run - INFO - read table from storage: create_base_documents.parquet
2024-10-23 17:13:51,265 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-23 17:13:51,267 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_documents.parquet
2024-10-23 17:13:51,295 - graphrag_api.index - INFO - All workflows completed successfully.
2024-10-24 10:26:50,267 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-24 10:26:50,267 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-24 10:36:57,067 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-24 10:36:57,075 - graphrag_api.index - INFO - Logging enabled at rag\output\20241024-103657\reports\indexing-engine.log
2024-10-24 10:36:57,078 - graphrag_api.index - INFO - Starting pipeline run for: 20241024-103657, self.dryrun=False
2024-10-24 10:36:57,079 - graphrag_api.index - INFO - Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "glm-4-flash",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "rag",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/openai/api/v2",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
2024-10-24 10:36:57,095 - graphrag.index.create_pipeline_config - INFO - skipping workflows 
2024-10-24 10:36:57,095 - graphrag.index.run - INFO - Running pipeline
2024-10-24 10:36:57,095 - graphrag.index.storage.file_pipeline_storage - INFO - Creating file storage at rag\output\20241024-103657\artifacts
2024-10-24 10:36:57,096 - graphrag.index.input.load_input - INFO - loading input from root_dir=input
2024-10-24 10:36:57,096 - graphrag.index.input.load_input - INFO - using file storage for input
2024-10-24 10:36:57,096 - graphrag.index.storage.file_pipeline_storage - INFO - search rag\input for files matching .*\.txt$
2024-10-24 10:36:57,097 - graphrag.index.input.text - INFO - found text files from input, found [('input.txt', {})]
2024-10-24 10:36:57,104 - graphrag.index.input.text - INFO - Found 1 files, loading 1
2024-10-24 10:36:57,105 - graphrag.index.workflows.load - INFO - Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
2024-10-24 10:36:57,105 - graphrag.index.run - INFO - Final # of rows loaded: 1
2024-10-24 10:36:57,229 - graphrag.index.run - INFO - Running workflow: create_base_text_units...
2024-10-24 10:36:57,229 - graphrag.index.run - INFO - dependencies for create_base_text_units: []
2024-10-24 10:36:57,230 - datashaper.workflow.workflow - INFO - executing verb orderby
2024-10-24 10:36:57,230 - datashaper.workflow.workflow - INFO - executing verb zip
2024-10-24 10:36:57,231 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 10:36:57,233 - datashaper.workflow.workflow - INFO - executing verb chunk
2024-10-24 10:36:57,378 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 10:36:57,379 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 10:36:57,380 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 10:36:57,381 - datashaper.workflow.workflow - INFO - executing verb genid
2024-10-24 10:36:57,382 - datashaper.workflow.workflow - INFO - executing verb unzip
2024-10-24 10:36:57,382 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-24 10:36:57,383 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 10:36:57,403 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_text_units.parquet
2024-10-24 10:36:57,536 - graphrag.index.run - INFO - Running workflow: create_base_extracted_entities...
2024-10-24 10:36:57,537 - graphrag.index.run - INFO - dependencies for create_base_extracted_entities: ['create_base_text_units']
2024-10-24 10:36:57,537 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-24 10:36:57,548 - datashaper.workflow.workflow - INFO - executing verb entity_extract
2024-10-24 10:36:57,553 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/zhipu/api/v2/chat/completions
2024-10-24 10:36:57,722 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for glm-4-flash: TPM=0, RPM=0
2024-10-24 10:36:57,722 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for glm-4-flash: 25
2024-10-24 10:36:57,798 - datashaper.workflow.workflow - INFO - executing verb merge_graphs
2024-10-24 10:36:57,818 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_extracted_entities.parquet
2024-10-24 10:36:57,939 - graphrag.index.run - INFO - Running workflow: create_summarized_entities...
2024-10-24 10:36:57,939 - graphrag.index.run - INFO - dependencies for create_summarized_entities: ['create_base_extracted_entities']
2024-10-24 10:36:57,940 - graphrag.index.run - INFO - read table from storage: create_base_extracted_entities.parquet
2024-10-24 10:36:57,949 - datashaper.workflow.workflow - INFO - executing verb summarize_descriptions
2024-10-24 10:36:58,052 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_summarized_entities.parquet
2024-10-24 10:36:58,175 - graphrag.index.run - INFO - Running workflow: create_base_entity_graph...
2024-10-24 10:36:58,176 - graphrag.index.run - INFO - dependencies for create_base_entity_graph: ['create_summarized_entities']
2024-10-24 10:36:58,176 - graphrag.index.run - INFO - read table from storage: create_summarized_entities.parquet
2024-10-24 10:36:58,182 - datashaper.workflow.workflow - INFO - executing verb cluster_graph
2024-10-24 10:36:58,244 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 10:36:58,246 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_entity_graph.parquet
2024-10-24 10:36:58,381 - graphrag.index.run - INFO - Running workflow: create_final_entities...
2024-10-24 10:36:58,382 - graphrag.index.run - INFO - dependencies for create_final_entities: ['create_base_entity_graph']
2024-10-24 10:36:58,383 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 10:36:58,393 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 10:36:58,411 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 10:36:58,411 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 10:36:58,412 - datashaper.workflow.workflow - INFO - executing verb dedupe
2024-10-24 10:36:58,412 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 10:36:58,412 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 10:36:58,418 - datashaper.workflow.workflow - INFO - executing verb text_split
2024-10-24 10:36:58,421 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 10:36:58,422 - datashaper.workflow.workflow - INFO - executing verb merge
2024-10-24 10:36:58,454 - datashaper.workflow.workflow - INFO - executing verb text_embed
2024-10-24 10:36:58,457 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/openai/api/v2
2024-10-24 10:36:58,627 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
2024-10-24 10:36:58,627 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for text-embedding-3-small: 25
2024-10-24 10:36:58,637 - graphrag.index.verbs.text.embed.strategies.openai - INFO - embedding 286 inputs via 286 snippets using 18 batches. max_batch_size=16, max_tokens=8191
2024-10-24 10:37:00,059 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-24 10:37:00,281 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.6410000000614673. input_tokens=555, output_tokens=0
2024-10-24 10:37:00,295 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 10:37:00,296 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 10:37:00,301 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_entities.parquet
2024-10-24 10:37:00,507 - graphrag.index.run - INFO - Running workflow: create_final_nodes...
2024-10-24 10:37:00,508 - graphrag.index.run - INFO - dependencies for create_final_nodes: ['create_base_entity_graph']
2024-10-24 10:37:00,508 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 10:37:00,515 - datashaper.workflow.workflow - INFO - executing verb layout_graph
2024-10-24 10:37:00,592 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 10:37:00,616 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 10:37:00,639 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 10:37:00,640 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 10:37:00,648 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 10:37:00,649 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 10:37:00,649 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 10:37:00,660 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 10:37:00,666 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 10:37:00,668 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_nodes.parquet
2024-10-24 10:37:00,800 - graphrag.index.run - INFO - Running workflow: create_final_communities...
2024-10-24 10:37:00,801 - graphrag.index.run - INFO - dependencies for create_final_communities: ['create_base_entity_graph']
2024-10-24 10:37:00,801 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 10:37:00,807 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 10:37:00,825 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 10:37:00,845 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 10:37:00,847 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 10:37:00,851 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 10:37:00,857 - datashaper.workflow.workflow - INFO - executing verb concat
2024-10-24 10:37:00,858 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 10:37:00,878 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 10:37:00,882 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 10:37:00,886 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 10:37:00,889 - datashaper.workflow.workflow - INFO - executing verb fill
2024-10-24 10:37:00,889 - datashaper.workflow.workflow - INFO - executing verb merge
2024-10-24 10:37:00,893 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-24 10:37:00,893 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 10:37:00,897 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_communities.parquet
2024-10-24 10:37:01,033 - graphrag.index.run - INFO - Running workflow: join_text_units_to_entity_ids...
2024-10-24 10:37:01,034 - graphrag.index.run - INFO - dependencies for join_text_units_to_entity_ids: ['create_final_entities']
2024-10-24 10:37:01,034 - graphrag.index.run - INFO - read table from storage: create_final_entities.parquet
2024-10-24 10:37:01,059 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 10:37:01,060 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 10:37:01,062 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 10:37:01,065 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table join_text_units_to_entity_ids.parquet
2024-10-24 10:37:01,195 - graphrag.index.run - INFO - Running workflow: create_final_relationships...
2024-10-24 10:37:01,196 - graphrag.index.run - INFO - dependencies for create_final_relationships: ['create_base_entity_graph', 'create_final_nodes']
2024-10-24 10:37:01,197 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 10:37:01,201 - graphrag.index.run - INFO - read table from storage: create_final_nodes.parquet
2024-10-24 10:37:01,213 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 10:37:01,231 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 10:37:01,237 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 10:37:01,238 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 10:37:01,242 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 10:37:01,243 - datashaper.workflow.workflow - INFO - executing verb compute_edge_combined_degree
2024-10-24 10:37:01,247 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 10:37:01,247 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 10:37:01,250 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_relationships.parquet
2024-10-24 10:37:01,379 - graphrag.index.run - INFO - Running workflow: join_text_units_to_relationship_ids...
2024-10-24 10:37:01,380 - graphrag.index.run - INFO - dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
2024-10-24 10:37:01,380 - graphrag.index.run - INFO - read table from storage: create_final_relationships.parquet
2024-10-24 10:37:01,389 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 10:37:01,389 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 10:37:01,391 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 10:37:01,393 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 10:37:01,395 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table join_text_units_to_relationship_ids.parquet
2024-10-24 10:37:01,521 - graphrag.index.run - INFO - Running workflow: create_final_community_reports...
2024-10-24 10:37:01,521 - graphrag.index.run - INFO - dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships']
2024-10-24 10:37:01,521 - graphrag.index.run - INFO - read table from storage: create_final_nodes.parquet
2024-10-24 10:37:01,528 - graphrag.index.run - INFO - read table from storage: create_final_relationships.parquet
2024-10-24 10:37:01,532 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports_nodes
2024-10-24 10:37:01,537 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports_edges
2024-10-24 10:37:01,540 - datashaper.workflow.workflow - INFO - executing verb restore_community_hierarchy
2024-10-24 10:37:01,544 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports
2024-10-24 10:37:01,545 - graphrag.index.verbs.graph.report.prepare_community_reports - INFO - Number of nodes at level=1 => 286
2024-10-24 10:37:01,591 - graphrag.index.verbs.graph.report.prepare_community_reports - INFO - Number of nodes at level=0 => 286
2024-10-24 10:37:01,629 - datashaper.workflow.workflow - INFO - executing verb create_community_reports
2024-10-24 10:37:17,531 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-24 10:37:17,534 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-24 10:37:17,535 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 15.859999999869615. input_tokens=2172, output_tokens=641
2024-10-24 10:37:17,537 - datashaper.workflow.workflow - INFO - executing verb window
2024-10-24 10:37:17,539 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_community_reports.parquet
2024-10-24 10:37:17,681 - graphrag.index.run - INFO - Running workflow: create_final_text_units...
2024-10-24 10:37:17,682 - graphrag.index.run - INFO - dependencies for create_final_text_units: ['join_text_units_to_relationship_ids', 'join_text_units_to_entity_ids', 'create_base_text_units']
2024-10-24 10:37:17,682 - graphrag.index.run - INFO - read table from storage: join_text_units_to_relationship_ids.parquet
2024-10-24 10:37:17,694 - graphrag.index.run - INFO - read table from storage: join_text_units_to_entity_ids.parquet
2024-10-24 10:37:17,705 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-24 10:37:17,708 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 10:37:17,709 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 10:37:17,710 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 10:37:17,713 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 10:37:17,718 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 10:37:17,719 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 10:37:17,721 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_text_units.parquet
2024-10-24 10:37:17,855 - graphrag.index.run - INFO - Running workflow: create_base_documents...
2024-10-24 10:37:17,855 - graphrag.index.run - INFO - dependencies for create_base_documents: ['create_final_text_units']
2024-10-24 10:37:17,855 - graphrag.index.run - INFO - read table from storage: create_final_text_units.parquet
2024-10-24 10:37:17,865 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 10:37:17,867 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 10:37:17,867 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 10:37:17,868 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 10:37:17,871 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 10:37:17,873 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 10:37:17,878 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 10:37:17,878 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 10:37:17,881 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_documents.parquet
2024-10-24 10:37:18,011 - graphrag.index.run - INFO - Running workflow: create_final_documents...
2024-10-24 10:37:18,012 - graphrag.index.run - INFO - dependencies for create_final_documents: ['create_base_documents']
2024-10-24 10:37:18,012 - graphrag.index.run - INFO - read table from storage: create_base_documents.parquet
2024-10-24 10:37:18,023 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 10:37:18,025 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_documents.parquet
2024-10-24 10:37:18,055 - graphrag_api.index - INFO - All workflows completed successfully.
2024-10-24 11:05:49,076 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-24 11:05:49,076 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-24 11:15:55,950 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-24 11:15:55,954 - graphrag_api.index - INFO - Logging enabled at rag\output\20241024-111555\reports\indexing-engine.log
2024-10-24 11:15:55,957 - graphrag_api.index - INFO - Starting pipeline run for: 20241024-111555, self.dryrun=False
2024-10-24 11:15:55,957 - graphrag_api.index - INFO - Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "glm-4-flash",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "rag",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/openai/api/v2",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
2024-10-24 11:15:55,958 - graphrag.index.create_pipeline_config - INFO - skipping workflows 
2024-10-24 11:15:55,959 - graphrag.index.run - INFO - Running pipeline
2024-10-24 11:15:55,959 - graphrag.index.storage.file_pipeline_storage - INFO - Creating file storage at rag\output\20241024-111555\artifacts
2024-10-24 11:15:55,959 - graphrag.index.input.load_input - INFO - loading input from root_dir=input
2024-10-24 11:15:55,959 - graphrag.index.input.load_input - INFO - using file storage for input
2024-10-24 11:15:55,960 - graphrag.index.storage.file_pipeline_storage - INFO - search rag\input for files matching .*\.txt$
2024-10-24 11:15:55,960 - graphrag.index.input.text - INFO - found text files from input, found [('input.txt', {})]
2024-10-24 11:15:55,965 - graphrag.index.input.text - INFO - Found 1 files, loading 1
2024-10-24 11:15:55,967 - graphrag.index.workflows.load - INFO - Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
2024-10-24 11:15:55,967 - graphrag.index.run - INFO - Final # of rows loaded: 1
2024-10-24 11:15:56,080 - graphrag.index.run - INFO - Running workflow: create_base_text_units...
2024-10-24 11:15:56,080 - graphrag.index.run - INFO - dependencies for create_base_text_units: []
2024-10-24 11:15:56,081 - datashaper.workflow.workflow - INFO - executing verb orderby
2024-10-24 11:15:56,081 - datashaper.workflow.workflow - INFO - executing verb zip
2024-10-24 11:15:56,082 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 11:15:56,084 - datashaper.workflow.workflow - INFO - executing verb chunk
2024-10-24 11:15:56,212 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 11:15:56,212 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 11:15:56,214 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 11:15:56,214 - datashaper.workflow.workflow - INFO - executing verb genid
2024-10-24 11:15:56,215 - datashaper.workflow.workflow - INFO - executing verb unzip
2024-10-24 11:15:56,216 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-24 11:15:56,216 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 11:15:56,220 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_text_units.parquet
2024-10-24 11:15:56,323 - graphrag.index.run - INFO - Running workflow: create_base_extracted_entities...
2024-10-24 11:15:56,324 - graphrag.index.run - INFO - dependencies for create_base_extracted_entities: ['create_base_text_units']
2024-10-24 11:15:56,324 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-24 11:15:56,339 - datashaper.workflow.workflow - INFO - executing verb entity_extract
2024-10-24 11:15:56,343 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/zhipu/api/v2/chat/completions
2024-10-24 11:15:56,500 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for glm-4-flash: TPM=0, RPM=0
2024-10-24 11:15:56,500 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for glm-4-flash: 25
2024-10-24 11:15:56,537 - datashaper.workflow.workflow - INFO - executing verb merge_graphs
2024-10-24 11:15:56,555 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_extracted_entities.parquet
2024-10-24 11:15:56,650 - graphrag.index.run - INFO - Running workflow: create_summarized_entities...
2024-10-24 11:15:56,650 - graphrag.index.run - INFO - dependencies for create_summarized_entities: ['create_base_extracted_entities']
2024-10-24 11:15:56,651 - graphrag.index.run - INFO - read table from storage: create_base_extracted_entities.parquet
2024-10-24 11:15:56,657 - datashaper.workflow.workflow - INFO - executing verb summarize_descriptions
2024-10-24 11:15:56,740 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_summarized_entities.parquet
2024-10-24 11:15:56,843 - graphrag.index.run - INFO - Running workflow: create_base_entity_graph...
2024-10-24 11:15:56,843 - graphrag.index.run - INFO - dependencies for create_base_entity_graph: ['create_summarized_entities']
2024-10-24 11:15:56,844 - graphrag.index.run - INFO - read table from storage: create_summarized_entities.parquet
2024-10-24 11:15:56,851 - datashaper.workflow.workflow - INFO - executing verb cluster_graph
2024-10-24 11:15:56,906 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 11:15:56,908 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_entity_graph.parquet
2024-10-24 11:15:57,014 - graphrag.index.run - INFO - Running workflow: create_final_entities...
2024-10-24 11:15:57,015 - graphrag.index.run - INFO - dependencies for create_final_entities: ['create_base_entity_graph']
2024-10-24 11:15:57,015 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 11:15:57,024 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 11:15:57,040 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 11:15:57,040 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 11:15:57,041 - datashaper.workflow.workflow - INFO - executing verb dedupe
2024-10-24 11:15:57,041 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 11:15:57,041 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 11:15:57,046 - datashaper.workflow.workflow - INFO - executing verb text_split
2024-10-24 11:15:57,049 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 11:15:57,050 - datashaper.workflow.workflow - INFO - executing verb merge
2024-10-24 11:15:57,082 - datashaper.workflow.workflow - INFO - executing verb text_embed
2024-10-24 11:15:57,083 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/openai/api/v2
2024-10-24 11:15:57,246 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
2024-10-24 11:15:57,247 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for text-embedding-3-small: 25
2024-10-24 11:15:57,257 - graphrag.index.verbs.text.embed.strategies.openai - INFO - embedding 286 inputs via 286 snippets using 18 batches. max_batch_size=16, max_tokens=8191
2024-10-24 11:15:58,623 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-24 11:15:58,785 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.5160000000614673. input_tokens=555, output_tokens=0
2024-10-24 11:15:58,798 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 11:15:58,798 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 11:15:58,804 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_entities.parquet
2024-10-24 11:15:58,959 - graphrag.index.run - INFO - Running workflow: create_final_nodes...
2024-10-24 11:15:58,959 - graphrag.index.run - INFO - dependencies for create_final_nodes: ['create_base_entity_graph']
2024-10-24 11:15:58,960 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 11:15:58,963 - datashaper.workflow.workflow - INFO - executing verb layout_graph
2024-10-24 11:15:59,029 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 11:15:59,047 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 11:15:59,064 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 11:15:59,071 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 11:15:59,071 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 11:15:59,072 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 11:15:59,072 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 11:15:59,074 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 11:15:59,079 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 11:15:59,080 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_nodes.parquet
2024-10-24 11:15:59,189 - graphrag.index.run - INFO - Running workflow: create_final_communities...
2024-10-24 11:15:59,189 - graphrag.index.run - INFO - dependencies for create_final_communities: ['create_base_entity_graph']
2024-10-24 11:15:59,189 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 11:15:59,192 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 11:15:59,207 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 11:15:59,221 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 11:15:59,223 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 11:15:59,228 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 11:15:59,232 - datashaper.workflow.workflow - INFO - executing verb concat
2024-10-24 11:15:59,232 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 11:15:59,253 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 11:15:59,257 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 11:15:59,260 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 11:15:59,263 - datashaper.workflow.workflow - INFO - executing verb fill
2024-10-24 11:15:59,263 - datashaper.workflow.workflow - INFO - executing verb merge
2024-10-24 11:15:59,268 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-24 11:15:59,268 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 11:15:59,270 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_communities.parquet
2024-10-24 11:15:59,395 - graphrag.index.run - INFO - Running workflow: join_text_units_to_entity_ids...
2024-10-24 11:15:59,396 - graphrag.index.run - INFO - dependencies for join_text_units_to_entity_ids: ['create_final_entities']
2024-10-24 11:15:59,397 - graphrag.index.run - INFO - read table from storage: create_final_entities.parquet
2024-10-24 11:15:59,416 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 11:15:59,417 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 11:15:59,418 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 11:15:59,421 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table join_text_units_to_entity_ids.parquet
2024-10-24 11:15:59,525 - graphrag.index.run - INFO - Running workflow: create_final_relationships...
2024-10-24 11:15:59,525 - graphrag.index.run - INFO - dependencies for create_final_relationships: ['create_final_nodes', 'create_base_entity_graph']
2024-10-24 11:15:59,526 - graphrag.index.run - INFO - read table from storage: create_final_nodes.parquet
2024-10-24 11:15:59,535 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 11:15:59,539 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 11:15:59,554 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 11:15:59,561 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 11:15:59,561 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 11:15:59,565 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 11:15:59,566 - datashaper.workflow.workflow - INFO - executing verb compute_edge_combined_degree
2024-10-24 11:15:59,569 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 11:15:59,569 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 11:15:59,571 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_relationships.parquet
2024-10-24 11:15:59,678 - graphrag.index.run - INFO - Running workflow: join_text_units_to_relationship_ids...
2024-10-24 11:15:59,679 - graphrag.index.run - INFO - dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
2024-10-24 11:15:59,679 - graphrag.index.run - INFO - read table from storage: create_final_relationships.parquet
2024-10-24 11:15:59,688 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 11:15:59,688 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 11:15:59,689 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 11:15:59,691 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 11:15:59,693 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table join_text_units_to_relationship_ids.parquet
2024-10-24 11:15:59,797 - graphrag.index.run - INFO - Running workflow: create_final_community_reports...
2024-10-24 11:15:59,797 - graphrag.index.run - INFO - dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes']
2024-10-24 11:15:59,798 - graphrag.index.run - INFO - read table from storage: create_final_relationships.parquet
2024-10-24 11:15:59,801 - graphrag.index.run - INFO - read table from storage: create_final_nodes.parquet
2024-10-24 11:15:59,805 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports_nodes
2024-10-24 11:15:59,811 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports_edges
2024-10-24 11:15:59,814 - datashaper.workflow.workflow - INFO - executing verb restore_community_hierarchy
2024-10-24 11:15:59,818 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports
2024-10-24 11:15:59,818 - graphrag.index.verbs.graph.report.prepare_community_reports - INFO - Number of nodes at level=1 => 286
2024-10-24 11:15:59,858 - graphrag.index.verbs.graph.report.prepare_community_reports - INFO - Number of nodes at level=0 => 286
2024-10-24 11:15:59,891 - datashaper.workflow.workflow - INFO - executing verb create_community_reports
2024-10-24 11:15:59,938 - datashaper.workflow.workflow - INFO - executing verb window
2024-10-24 11:15:59,940 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_community_reports.parquet
2024-10-24 11:16:00,057 - graphrag.index.run - INFO - Running workflow: create_final_text_units...
2024-10-24 11:16:00,058 - graphrag.index.run - INFO - dependencies for create_final_text_units: ['join_text_units_to_entity_ids', 'create_base_text_units', 'join_text_units_to_relationship_ids']
2024-10-24 11:16:00,058 - graphrag.index.run - INFO - read table from storage: join_text_units_to_entity_ids.parquet
2024-10-24 11:16:00,067 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-24 11:16:00,070 - graphrag.index.run - INFO - read table from storage: join_text_units_to_relationship_ids.parquet
2024-10-24 11:16:00,079 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 11:16:00,079 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 11:16:00,079 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 11:16:00,083 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 11:16:00,087 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 11:16:00,089 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 11:16:00,090 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_text_units.parquet
2024-10-24 11:16:00,199 - graphrag.index.run - INFO - Running workflow: create_base_documents...
2024-10-24 11:16:00,200 - graphrag.index.run - INFO - dependencies for create_base_documents: ['create_final_text_units']
2024-10-24 11:16:00,200 - graphrag.index.run - INFO - read table from storage: create_final_text_units.parquet
2024-10-24 11:16:00,208 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 11:16:00,209 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 11:16:00,209 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 11:16:00,210 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 11:16:00,213 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 11:16:00,214 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 11:16:00,218 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 11:16:00,219 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 11:16:00,221 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_documents.parquet
2024-10-24 11:16:00,320 - graphrag.index.run - INFO - Running workflow: create_final_documents...
2024-10-24 11:16:00,321 - graphrag.index.run - INFO - dependencies for create_final_documents: ['create_base_documents']
2024-10-24 11:16:00,321 - graphrag.index.run - INFO - read table from storage: create_base_documents.parquet
2024-10-24 11:16:00,331 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 11:16:00,332 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_documents.parquet
2024-10-24 11:16:00,362 - graphrag_api.index - INFO - All workflows completed successfully.
2024-10-24 14:21:43,015 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-24 14:21:43,015 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-24 14:21:50,244 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT chunk_id IF NOT EXISTS FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT chunk_id FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique'
2024-10-24 14:21:50,249 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT document_id IF NOT EXISTS FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT document_id FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint document_id if not exists for (d:__Document__) require d.id is unique'
2024-10-24 14:21:50,254 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (c:__Community__) require c.community is unique'
2024-10-24 14:21:50,257 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (e:__Entity__) require e.id is unique'
2024-10-24 14:21:50,260 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Entity__) require e.name is unique'
2024-10-24 14:21:50,262 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Covariate__) REQUIRE (e.title) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Covariate__) require e.title is unique'
2024-10-24 14:21:50,274 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT related_id IF NOT EXISTS FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT related_id FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique'
2024-10-24 14:23:24,067 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-24 14:23:24,067 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-24 14:23:31,086 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT chunk_id IF NOT EXISTS FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT chunk_id FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique'
2024-10-24 14:23:31,088 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT document_id IF NOT EXISTS FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT document_id FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint document_id if not exists for (d:__Document__) require d.id is unique'
2024-10-24 14:23:31,089 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (c:__Community__) require c.community is unique'
2024-10-24 14:23:31,091 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (e:__Entity__) require e.id is unique'
2024-10-24 14:23:31,092 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Entity__) require e.name is unique'
2024-10-24 14:23:31,093 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Covariate__) REQUIRE (e.title) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Covariate__) require e.title is unique'
2024-10-24 14:23:31,094 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT related_id IF NOT EXISTS FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT related_id FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique'
2024-10-24 14:23:31,096 - root - INFO - Deleted folder: ./rag\output\20241024-103657
2024-10-24 14:23:31,097 - root - INFO - Deleted folder: ./rag\output\20241024-111555
2024-10-24 14:27:31,822 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-24 14:27:31,822 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-24 14:28:43,872 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-24 14:28:43,872 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-24 14:38:51,306 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-24 14:38:51,314 - graphrag_api.index - INFO - Logging enabled at rag\output\20241024-143851\reports\indexing-engine.log
2024-10-24 14:38:51,317 - graphrag_api.index - INFO - Starting pipeline run for: 20241024-143851, self.dryrun=False
2024-10-24 14:38:51,317 - graphrag_api.index - INFO - Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "glm-4-flash",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "rag",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/openai/api/v2",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
2024-10-24 14:38:51,331 - graphrag.index.create_pipeline_config - INFO - skipping workflows 
2024-10-24 14:38:51,331 - graphrag.index.run - INFO - Running pipeline
2024-10-24 14:38:51,331 - graphrag.index.storage.file_pipeline_storage - INFO - Creating file storage at rag\output\20241024-143851\artifacts
2024-10-24 14:38:51,331 - graphrag.index.input.load_input - INFO - loading input from root_dir=input
2024-10-24 14:38:51,331 - graphrag.index.input.load_input - INFO - using file storage for input
2024-10-24 14:38:51,332 - graphrag.index.storage.file_pipeline_storage - INFO - search rag\input for files matching .*\.txt$
2024-10-24 14:38:51,332 - graphrag.index.input.text - INFO - found text files from input, found [('input.txt', {})]
2024-10-24 14:38:51,337 - graphrag.index.input.text - INFO - Found 1 files, loading 1
2024-10-24 14:38:51,338 - graphrag.index.workflows.load - INFO - Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
2024-10-24 14:38:51,338 - graphrag.index.run - INFO - Final # of rows loaded: 1
2024-10-24 14:38:51,446 - graphrag.index.run - INFO - Running workflow: create_base_text_units...
2024-10-24 14:38:51,446 - graphrag.index.run - INFO - dependencies for create_base_text_units: []
2024-10-24 14:38:51,447 - datashaper.workflow.workflow - INFO - executing verb orderby
2024-10-24 14:38:51,447 - datashaper.workflow.workflow - INFO - executing verb zip
2024-10-24 14:38:51,448 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 14:38:51,450 - datashaper.workflow.workflow - INFO - executing verb chunk
2024-10-24 14:38:51,582 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 14:38:51,583 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 14:38:51,584 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 14:38:51,585 - datashaper.workflow.workflow - INFO - executing verb genid
2024-10-24 14:38:51,586 - datashaper.workflow.workflow - INFO - executing verb unzip
2024-10-24 14:38:51,587 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-24 14:38:51,587 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 14:38:51,612 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_text_units.parquet
2024-10-24 14:38:51,721 - graphrag.index.run - INFO - Running workflow: create_base_extracted_entities...
2024-10-24 14:38:51,721 - graphrag.index.run - INFO - dependencies for create_base_extracted_entities: ['create_base_text_units']
2024-10-24 14:38:51,722 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-24 14:38:51,732 - datashaper.workflow.workflow - INFO - executing verb entity_extract
2024-10-24 14:38:51,736 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/zhipu/api/v2/chat/completions
2024-10-24 14:38:51,900 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for glm-4-flash: TPM=0, RPM=0
2024-10-24 14:38:51,900 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for glm-4-flash: 25
2024-10-24 14:38:51,958 - datashaper.workflow.workflow - INFO - executing verb merge_graphs
2024-10-24 14:38:51,976 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_extracted_entities.parquet
2024-10-24 14:38:52,077 - graphrag.index.run - INFO - Running workflow: create_summarized_entities...
2024-10-24 14:38:52,078 - graphrag.index.run - INFO - dependencies for create_summarized_entities: ['create_base_extracted_entities']
2024-10-24 14:38:52,078 - graphrag.index.run - INFO - read table from storage: create_base_extracted_entities.parquet
2024-10-24 14:38:52,086 - datashaper.workflow.workflow - INFO - executing verb summarize_descriptions
2024-10-24 14:38:57,594 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-24 14:38:57,597 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "summarize" with 0 retries took 5.4530000002123415. input_tokens=185, output_tokens=108
2024-10-24 14:38:57,609 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_summarized_entities.parquet
2024-10-24 14:38:57,712 - graphrag.index.run - INFO - Running workflow: create_base_entity_graph...
2024-10-24 14:38:57,712 - graphrag.index.run - INFO - dependencies for create_base_entity_graph: ['create_summarized_entities']
2024-10-24 14:38:57,712 - graphrag.index.run - INFO - read table from storage: create_summarized_entities.parquet
2024-10-24 14:38:57,721 - datashaper.workflow.workflow - INFO - executing verb cluster_graph
2024-10-24 14:38:57,775 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 14:38:57,777 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_entity_graph.parquet
2024-10-24 14:38:57,883 - graphrag.index.run - INFO - Running workflow: create_final_entities...
2024-10-24 14:38:57,884 - graphrag.index.run - INFO - dependencies for create_final_entities: ['create_base_entity_graph']
2024-10-24 14:38:57,884 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 14:38:57,893 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 14:38:57,909 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 14:38:57,909 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 14:38:57,910 - datashaper.workflow.workflow - INFO - executing verb dedupe
2024-10-24 14:38:57,911 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 14:38:57,911 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 14:38:57,916 - datashaper.workflow.workflow - INFO - executing verb text_split
2024-10-24 14:38:57,920 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 14:38:57,920 - datashaper.workflow.workflow - INFO - executing verb merge
2024-10-24 14:38:57,950 - datashaper.workflow.workflow - INFO - executing verb text_embed
2024-10-24 14:38:57,952 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/openai/api/v2
2024-10-24 14:38:58,110 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
2024-10-24 14:38:58,110 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for text-embedding-3-small: 25
2024-10-24 14:38:58,121 - graphrag.index.verbs.text.embed.strategies.openai - INFO - embedding 286 inputs via 286 snippets using 18 batches. max_batch_size=16, max_tokens=8191
2024-10-24 14:38:59,563 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-24 14:38:59,736 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.6089999999385327. input_tokens=757, output_tokens=0
2024-10-24 14:38:59,759 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-24 14:38:59,973 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.843000000109896. input_tokens=556, output_tokens=0
2024-10-24 14:38:59,985 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 14:38:59,986 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 14:38:59,991 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_entities.parquet
2024-10-24 14:39:00,151 - graphrag.index.run - INFO - Running workflow: create_final_nodes...
2024-10-24 14:39:00,151 - graphrag.index.run - INFO - dependencies for create_final_nodes: ['create_base_entity_graph']
2024-10-24 14:39:00,151 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 14:39:00,155 - datashaper.workflow.workflow - INFO - executing verb layout_graph
2024-10-24 14:39:00,223 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 14:39:00,243 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 14:39:00,263 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 14:39:00,264 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 14:39:00,271 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 14:39:00,271 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 14:39:00,272 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 14:39:00,283 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 14:39:00,287 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 14:39:00,289 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_nodes.parquet
2024-10-24 14:39:00,399 - graphrag.index.run - INFO - Running workflow: create_final_communities...
2024-10-24 14:39:00,400 - graphrag.index.run - INFO - dependencies for create_final_communities: ['create_base_entity_graph']
2024-10-24 14:39:00,400 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 14:39:00,403 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 14:39:00,420 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 14:39:00,436 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 14:39:00,438 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 14:39:00,442 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 14:39:00,447 - datashaper.workflow.workflow - INFO - executing verb concat
2024-10-24 14:39:00,447 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 14:39:00,465 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 14:39:00,468 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 14:39:00,472 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 14:39:00,475 - datashaper.workflow.workflow - INFO - executing verb fill
2024-10-24 14:39:00,475 - datashaper.workflow.workflow - INFO - executing verb merge
2024-10-24 14:39:00,479 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-24 14:39:00,479 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 14:39:00,481 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_communities.parquet
2024-10-24 14:39:00,606 - graphrag.index.run - INFO - Running workflow: join_text_units_to_entity_ids...
2024-10-24 14:39:00,606 - graphrag.index.run - INFO - dependencies for join_text_units_to_entity_ids: ['create_final_entities']
2024-10-24 14:39:00,606 - graphrag.index.run - INFO - read table from storage: create_final_entities.parquet
2024-10-24 14:39:00,628 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 14:39:00,629 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 14:39:00,630 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 14:39:00,634 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table join_text_units_to_entity_ids.parquet
2024-10-24 14:39:00,741 - graphrag.index.run - INFO - Running workflow: create_final_relationships...
2024-10-24 14:39:00,742 - graphrag.index.run - INFO - dependencies for create_final_relationships: ['create_final_nodes', 'create_base_entity_graph']
2024-10-24 14:39:00,742 - graphrag.index.run - INFO - read table from storage: create_final_nodes.parquet
2024-10-24 14:39:00,755 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 14:39:00,758 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 14:39:00,775 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 14:39:00,782 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 14:39:00,782 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 14:39:00,787 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 14:39:00,788 - datashaper.workflow.workflow - INFO - executing verb compute_edge_combined_degree
2024-10-24 14:39:00,790 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 14:39:00,791 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 14:39:00,792 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_relationships.parquet
2024-10-24 14:39:00,902 - graphrag.index.run - INFO - Running workflow: join_text_units_to_relationship_ids...
2024-10-24 14:39:00,903 - graphrag.index.run - INFO - dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
2024-10-24 14:39:00,903 - graphrag.index.run - INFO - read table from storage: create_final_relationships.parquet
2024-10-24 14:39:00,910 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 14:39:00,911 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 14:39:00,912 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 14:39:00,914 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 14:39:00,916 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table join_text_units_to_relationship_ids.parquet
2024-10-24 14:39:01,021 - graphrag.index.run - INFO - Running workflow: create_final_community_reports...
2024-10-24 14:39:01,021 - graphrag.index.run - INFO - dependencies for create_final_community_reports: ['create_final_nodes', 'create_final_relationships']
2024-10-24 14:39:01,021 - graphrag.index.run - INFO - read table from storage: create_final_nodes.parquet
2024-10-24 14:39:01,025 - graphrag.index.run - INFO - read table from storage: create_final_relationships.parquet
2024-10-24 14:39:01,028 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports_nodes
2024-10-24 14:39:01,034 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports_edges
2024-10-24 14:39:01,037 - datashaper.workflow.workflow - INFO - executing verb restore_community_hierarchy
2024-10-24 14:39:01,040 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports
2024-10-24 14:39:01,041 - graphrag.index.verbs.graph.report.prepare_community_reports - INFO - Number of nodes at level=1 => 286
2024-10-24 14:39:01,081 - graphrag.index.verbs.graph.report.prepare_community_reports - INFO - Number of nodes at level=0 => 286
2024-10-24 14:39:01,115 - datashaper.workflow.workflow - INFO - executing verb create_community_reports
2024-10-24 14:39:18,899 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-24 14:39:18,900 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-24 14:39:18,901 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 17.780999999959022. input_tokens=2342, output_tokens=641
2024-10-24 14:39:38,591 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-24 14:39:38,592 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-24 14:39:38,592 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 19.687000000150874. input_tokens=3083, output_tokens=767
2024-10-24 14:39:38,594 - datashaper.workflow.workflow - INFO - executing verb window
2024-10-24 14:39:38,596 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_community_reports.parquet
2024-10-24 14:39:38,713 - graphrag.index.run - INFO - Running workflow: create_final_text_units...
2024-10-24 14:39:38,713 - graphrag.index.run - INFO - dependencies for create_final_text_units: ['join_text_units_to_relationship_ids', 'create_base_text_units', 'join_text_units_to_entity_ids']
2024-10-24 14:39:38,714 - graphrag.index.run - INFO - read table from storage: join_text_units_to_relationship_ids.parquet
2024-10-24 14:39:38,722 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-24 14:39:38,724 - graphrag.index.run - INFO - read table from storage: join_text_units_to_entity_ids.parquet
2024-10-24 14:39:38,735 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 14:39:38,735 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 14:39:38,736 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 14:39:38,739 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 14:39:38,743 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 14:39:38,745 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 14:39:38,746 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_text_units.parquet
2024-10-24 14:39:38,854 - graphrag.index.run - INFO - Running workflow: create_base_documents...
2024-10-24 14:39:38,855 - graphrag.index.run - INFO - dependencies for create_base_documents: ['create_final_text_units']
2024-10-24 14:39:38,855 - graphrag.index.run - INFO - read table from storage: create_final_text_units.parquet
2024-10-24 14:39:38,864 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 14:39:38,865 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 14:39:38,865 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 14:39:38,866 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 14:39:38,869 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 14:39:38,870 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 14:39:38,874 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 14:39:38,874 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 14:39:38,876 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_documents.parquet
2024-10-24 14:39:38,978 - graphrag.index.run - INFO - Running workflow: create_final_documents...
2024-10-24 14:39:38,979 - graphrag.index.run - INFO - dependencies for create_final_documents: ['create_base_documents']
2024-10-24 14:39:38,979 - graphrag.index.run - INFO - read table from storage: create_base_documents.parquet
2024-10-24 14:39:38,989 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 14:39:38,991 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_documents.parquet
2024-10-24 14:39:39,021 - graphrag_api.index - INFO - All workflows completed successfully.
2024-10-24 14:53:53,330 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-24 14:53:53,330 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-24 14:56:00,791 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-24 14:56:00,791 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-24 15:06:08,144 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-24 15:06:08,152 - graphrag_api.index - INFO - Logging enabled at rag\output\20241024-150608\reports\indexing-engine.log
2024-10-24 15:06:08,157 - graphrag_api.index - INFO - Starting pipeline run for: 20241024-150608, self.dryrun=False
2024-10-24 15:06:08,157 - graphrag_api.index - INFO - Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "glm-4-flash",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "rag",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/openai/api/v2",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
2024-10-24 15:06:08,161 - graphrag.index.create_pipeline_config - INFO - skipping workflows 
2024-10-24 15:06:08,161 - graphrag.index.run - INFO - Running pipeline
2024-10-24 15:06:08,161 - graphrag.index.storage.file_pipeline_storage - INFO - Creating file storage at rag\output\20241024-150608\artifacts
2024-10-24 15:06:08,165 - graphrag.index.input.load_input - INFO - loading input from root_dir=input
2024-10-24 15:06:08,165 - graphrag.index.input.load_input - INFO - using file storage for input
2024-10-24 15:06:08,166 - graphrag.index.storage.file_pipeline_storage - INFO - search rag\input for files matching .*\.txt$
2024-10-24 15:06:08,166 - graphrag.index.input.text - INFO - found text files from input, found [('input.txt', {})]
2024-10-24 15:06:08,177 - graphrag.index.input.text - INFO - Found 1 files, loading 1
2024-10-24 15:06:08,179 - graphrag.index.workflows.load - INFO - Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
2024-10-24 15:06:08,180 - graphrag.index.run - INFO - Final # of rows loaded: 1
2024-10-24 15:06:08,376 - graphrag.index.run - INFO - Running workflow: create_base_text_units...
2024-10-24 15:06:08,377 - graphrag.index.run - INFO - dependencies for create_base_text_units: []
2024-10-24 15:06:08,378 - datashaper.workflow.workflow - INFO - executing verb orderby
2024-10-24 15:06:08,378 - datashaper.workflow.workflow - INFO - executing verb zip
2024-10-24 15:06:08,380 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 15:06:08,384 - datashaper.workflow.workflow - INFO - executing verb chunk
2024-10-24 15:06:08,624 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:06:08,628 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 15:06:08,630 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:06:08,631 - datashaper.workflow.workflow - INFO - executing verb genid
2024-10-24 15:06:08,633 - datashaper.workflow.workflow - INFO - executing verb unzip
2024-10-24 15:06:08,634 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-24 15:06:08,635 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 15:06:08,642 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_text_units.parquet
2024-10-24 15:06:08,894 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT chunk_id IF NOT EXISTS FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT chunk_id FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique'
2024-10-24 15:06:08,897 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT document_id IF NOT EXISTS FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT document_id FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint document_id if not exists for (d:__Document__) require d.id is unique'
2024-10-24 15:06:08,902 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (c:__Community__) require c.community is unique'
2024-10-24 15:06:08,905 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (e:__Entity__) require e.id is unique'
2024-10-24 15:06:08,910 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Entity__) require e.name is unique'
2024-10-24 15:06:08,913 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Covariate__) REQUIRE (e.title) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Covariate__) require e.title is unique'
2024-10-24 15:06:08,915 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT related_id IF NOT EXISTS FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT related_id FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique'
2024-10-24 15:06:08,920 - root - INFO - Deleted folder: ./rag\output\20241023-171321
2024-10-24 15:06:08,923 - root - INFO - Deleted folder: ./rag\output\20241024-143851
2024-10-24 15:06:08,950 - graphrag.index.run - INFO - Running workflow: create_base_extracted_entities...
2024-10-24 15:06:08,952 - graphrag.index.run - INFO - dependencies for create_base_extracted_entities: ['create_base_text_units']
2024-10-24 15:06:08,952 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-24 15:06:08,968 - datashaper.workflow.workflow - INFO - executing verb entity_extract
2024-10-24 15:06:08,974 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/zhipu/api/v2/chat/completions
2024-10-24 15:06:09,284 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for glm-4-flash: TPM=0, RPM=0
2024-10-24 15:06:09,284 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for glm-4-flash: 25
2024-10-24 15:06:09,369 - datashaper.workflow.workflow - INFO - executing verb merge_graphs
2024-10-24 15:06:09,406 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_extracted_entities.parquet
2024-10-24 15:06:09,631 - graphrag.index.run - INFO - Running workflow: create_summarized_entities...
2024-10-24 15:06:09,632 - graphrag.index.run - INFO - dependencies for create_summarized_entities: ['create_base_extracted_entities']
2024-10-24 15:06:09,632 - graphrag.index.run - INFO - read table from storage: create_base_extracted_entities.parquet
2024-10-24 15:06:09,644 - datashaper.workflow.workflow - INFO - executing verb summarize_descriptions
2024-10-24 15:06:09,814 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_summarized_entities.parquet
2024-10-24 15:06:10,039 - graphrag.index.run - INFO - Running workflow: create_base_entity_graph...
2024-10-24 15:06:10,041 - graphrag.index.run - INFO - dependencies for create_base_entity_graph: ['create_summarized_entities']
2024-10-24 15:06:10,041 - graphrag.index.run - INFO - read table from storage: create_summarized_entities.parquet
2024-10-24 15:06:10,051 - datashaper.workflow.workflow - INFO - executing verb cluster_graph
2024-10-24 15:06:10,133 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:06:10,135 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_entity_graph.parquet
2024-10-24 15:06:10,331 - graphrag.index.run - INFO - Running workflow: create_final_entities...
2024-10-24 15:06:10,332 - graphrag.index.run - INFO - dependencies for create_final_entities: ['create_base_entity_graph']
2024-10-24 15:06:10,332 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 15:06:10,340 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 15:06:10,357 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:06:10,358 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:06:10,359 - datashaper.workflow.workflow - INFO - executing verb dedupe
2024-10-24 15:06:10,361 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:06:10,363 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 15:06:10,375 - datashaper.workflow.workflow - INFO - executing verb text_split
2024-10-24 15:06:10,386 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 15:06:10,387 - datashaper.workflow.workflow - INFO - executing verb merge
2024-10-24 15:06:10,465 - datashaper.workflow.workflow - INFO - executing verb text_embed
2024-10-24 15:06:10,466 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/openai/api/v2
2024-10-24 15:06:10,755 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
2024-10-24 15:06:10,755 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for text-embedding-3-small: 25
2024-10-24 15:06:10,777 - graphrag.index.verbs.text.embed.strategies.openai - INFO - embedding 286 inputs via 286 snippets using 18 batches. max_batch_size=16, max_tokens=8191
2024-10-24 15:06:12,131 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-24 15:06:12,332 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.547000000020489. input_tokens=556, output_tokens=0
2024-10-24 15:06:12,404 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-24 15:06:12,615 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.828999999910593. input_tokens=241, output_tokens=0
2024-10-24 15:06:12,634 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 15:06:12,636 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 15:06:12,646 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_entities.parquet
2024-10-24 15:06:12,953 - graphrag.index.run - INFO - Running workflow: create_final_nodes...
2024-10-24 15:06:12,953 - graphrag.index.run - INFO - dependencies for create_final_nodes: ['create_base_entity_graph']
2024-10-24 15:06:12,953 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 15:06:12,959 - datashaper.workflow.workflow - INFO - executing verb layout_graph
2024-10-24 15:06:13,098 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 15:06:13,137 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 15:06:13,174 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 15:06:13,187 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 15:06:13,188 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:06:13,188 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:06:13,189 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 15:06:13,196 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 15:06:13,199 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:06:13,203 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_nodes.parquet
2024-10-24 15:06:13,440 - graphrag.index.run - INFO - Running workflow: create_final_communities...
2024-10-24 15:06:13,441 - graphrag.index.run - INFO - dependencies for create_final_communities: ['create_base_entity_graph']
2024-10-24 15:06:13,443 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 15:06:13,449 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 15:06:13,481 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 15:06:13,513 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 15:06:13,516 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 15:06:13,525 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 15:06:13,533 - datashaper.workflow.workflow - INFO - executing verb concat
2024-10-24 15:06:13,534 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 15:06:13,568 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 15:06:13,574 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 15:06:13,583 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 15:06:13,588 - datashaper.workflow.workflow - INFO - executing verb fill
2024-10-24 15:06:13,589 - datashaper.workflow.workflow - INFO - executing verb merge
2024-10-24 15:06:13,597 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-24 15:06:13,597 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:06:13,601 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_communities.parquet
2024-10-24 15:06:13,852 - graphrag.index.run - INFO - Running workflow: join_text_units_to_entity_ids...
2024-10-24 15:06:13,852 - graphrag.index.run - INFO - dependencies for join_text_units_to_entity_ids: ['create_final_entities']
2024-10-24 15:06:13,853 - graphrag.index.run - INFO - read table from storage: create_final_entities.parquet
2024-10-24 15:06:13,885 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:06:13,886 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 15:06:13,889 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 15:06:13,895 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table join_text_units_to_entity_ids.parquet
2024-10-24 15:06:14,097 - graphrag.index.run - INFO - Running workflow: create_final_relationships...
2024-10-24 15:06:14,098 - graphrag.index.run - INFO - dependencies for create_final_relationships: ['create_final_nodes', 'create_base_entity_graph']
2024-10-24 15:06:14,099 - graphrag.index.run - INFO - read table from storage: create_final_nodes.parquet
2024-10-24 15:06:14,113 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 15:06:14,118 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 15:06:14,157 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 15:06:14,169 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:06:14,170 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 15:06:14,177 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 15:06:14,178 - datashaper.workflow.workflow - INFO - executing verb compute_edge_combined_degree
2024-10-24 15:06:14,185 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 15:06:14,185 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 15:06:14,187 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_relationships.parquet
2024-10-24 15:06:14,445 - graphrag.index.run - INFO - Running workflow: join_text_units_to_relationship_ids...
2024-10-24 15:06:14,445 - graphrag.index.run - INFO - dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
2024-10-24 15:06:14,446 - graphrag.index.run - INFO - read table from storage: create_final_relationships.parquet
2024-10-24 15:06:14,457 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:06:14,458 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 15:06:14,461 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 15:06:14,464 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:06:14,467 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table join_text_units_to_relationship_ids.parquet
2024-10-24 15:06:14,686 - graphrag.index.run - INFO - Running workflow: create_final_community_reports...
2024-10-24 15:06:14,687 - graphrag.index.run - INFO - dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes']
2024-10-24 15:06:14,687 - graphrag.index.run - INFO - read table from storage: create_final_relationships.parquet
2024-10-24 15:06:14,693 - graphrag.index.run - INFO - read table from storage: create_final_nodes.parquet
2024-10-24 15:06:14,699 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports_nodes
2024-10-24 15:06:14,712 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports_edges
2024-10-24 15:06:14,718 - datashaper.workflow.workflow - INFO - executing verb restore_community_hierarchy
2024-10-24 15:06:14,726 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports
2024-10-24 15:06:14,726 - graphrag.index.verbs.graph.report.prepare_community_reports - INFO - Number of nodes at level=1 => 286
2024-10-24 15:06:14,806 - graphrag.index.verbs.graph.report.prepare_community_reports - INFO - Number of nodes at level=0 => 286
2024-10-24 15:06:14,881 - datashaper.workflow.workflow - INFO - executing verb create_community_reports
2024-10-24 15:06:31,096 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-24 15:06:31,101 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-24 15:06:31,103 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 16.140999999828637. input_tokens=2509, output_tokens=647
2024-10-24 15:06:34,149 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-24 15:06:34,150 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-24 15:06:34,152 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 19.20299999997951. input_tokens=2227, output_tokens=663
2024-10-24 15:06:34,155 - datashaper.workflow.workflow - INFO - executing verb window
2024-10-24 15:06:34,158 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_community_reports.parquet
2024-10-24 15:06:34,303 - graphrag.index.run - INFO - Running workflow: create_final_text_units...
2024-10-24 15:06:34,304 - graphrag.index.run - INFO - dependencies for create_final_text_units: ['join_text_units_to_relationship_ids', 'create_base_text_units', 'join_text_units_to_entity_ids']
2024-10-24 15:06:34,304 - graphrag.index.run - INFO - read table from storage: join_text_units_to_relationship_ids.parquet
2024-10-24 15:06:34,314 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-24 15:06:34,318 - graphrag.index.run - INFO - read table from storage: join_text_units_to_entity_ids.parquet
2024-10-24 15:06:34,331 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:06:34,332 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:06:34,333 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 15:06:34,347 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 15:06:34,357 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 15:06:34,360 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:06:34,363 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_text_units.parquet
2024-10-24 15:06:34,566 - graphrag.index.run - INFO - Running workflow: create_base_documents...
2024-10-24 15:06:34,566 - graphrag.index.run - INFO - dependencies for create_base_documents: ['create_final_text_units']
2024-10-24 15:06:34,566 - graphrag.index.run - INFO - read table from storage: create_final_text_units.parquet
2024-10-24 15:06:34,575 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 15:06:34,576 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:06:34,577 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:06:34,577 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 15:06:34,582 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 15:06:34,584 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 15:06:34,589 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:06:34,590 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 15:06:34,593 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_documents.parquet
2024-10-24 15:06:34,793 - graphrag.index.run - INFO - Running workflow: create_final_documents...
2024-10-24 15:06:34,794 - graphrag.index.run - INFO - dependencies for create_final_documents: ['create_base_documents']
2024-10-24 15:06:34,794 - graphrag.index.run - INFO - read table from storage: create_base_documents.parquet
2024-10-24 15:06:34,806 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:06:34,809 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_documents.parquet
2024-10-24 15:06:34,860 - graphrag_api.index - INFO - All workflows completed successfully.
2024-10-24 15:14:16,116 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-24 15:14:16,116 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-24 15:24:23,666 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-24 15:24:23,672 - graphrag_api.index - INFO - Logging enabled at rag\output\20241024-152423\reports\indexing-engine.log
2024-10-24 15:24:23,676 - graphrag_api.index - INFO - Starting pipeline run for: 20241024-152423, self.dryrun=False
2024-10-24 15:24:23,676 - graphrag_api.index - INFO - Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "glm-4-flash",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "rag",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/openai/api/v2",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
2024-10-24 15:24:23,678 - graphrag.index.create_pipeline_config - INFO - skipping workflows 
2024-10-24 15:24:23,678 - graphrag.index.run - INFO - Running pipeline
2024-10-24 15:24:23,678 - graphrag.index.storage.file_pipeline_storage - INFO - Creating file storage at rag\output\20241024-152423\artifacts
2024-10-24 15:24:23,678 - graphrag.index.input.load_input - INFO - loading input from root_dir=input
2024-10-24 15:24:23,679 - graphrag.index.input.load_input - INFO - using file storage for input
2024-10-24 15:24:23,679 - graphrag.index.storage.file_pipeline_storage - INFO - search rag\input for files matching .*\.txt$
2024-10-24 15:24:23,679 - graphrag.index.input.text - INFO - found text files from input, found [('input.txt', {})]
2024-10-24 15:24:23,684 - graphrag.index.input.text - INFO - Found 1 files, loading 1
2024-10-24 15:24:23,686 - graphrag.index.workflows.load - INFO - Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
2024-10-24 15:24:23,686 - graphrag.index.run - INFO - Final # of rows loaded: 1
2024-10-24 15:24:23,850 - graphrag.index.run - INFO - Running workflow: create_base_text_units...
2024-10-24 15:24:23,851 - graphrag.index.run - INFO - dependencies for create_base_text_units: []
2024-10-24 15:24:23,851 - datashaper.workflow.workflow - INFO - executing verb orderby
2024-10-24 15:24:23,852 - datashaper.workflow.workflow - INFO - executing verb zip
2024-10-24 15:24:23,853 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 15:24:23,857 - datashaper.workflow.workflow - INFO - executing verb chunk
2024-10-24 15:24:24,046 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:24:24,047 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 15:24:24,049 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:24:24,049 - datashaper.workflow.workflow - INFO - executing verb genid
2024-10-24 15:24:24,051 - datashaper.workflow.workflow - INFO - executing verb unzip
2024-10-24 15:24:24,052 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-24 15:24:24,052 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 15:24:24,058 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_text_units.parquet
2024-10-24 15:24:24,211 - graphrag.index.run - INFO - Running workflow: create_base_extracted_entities...
2024-10-24 15:24:24,212 - graphrag.index.run - INFO - dependencies for create_base_extracted_entities: ['create_base_text_units']
2024-10-24 15:24:24,212 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-24 15:24:24,224 - datashaper.workflow.workflow - INFO - executing verb entity_extract
2024-10-24 15:24:24,228 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/zhipu/api/v2/chat/completions
2024-10-24 15:24:24,475 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for glm-4-flash: TPM=0, RPM=0
2024-10-24 15:24:24,475 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for glm-4-flash: 25
2024-10-24 15:24:24,536 - datashaper.workflow.workflow - INFO - executing verb merge_graphs
2024-10-24 15:24:24,567 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_extracted_entities.parquet
2024-10-24 15:24:24,706 - graphrag.index.run - INFO - Running workflow: create_summarized_entities...
2024-10-24 15:24:24,707 - graphrag.index.run - INFO - dependencies for create_summarized_entities: ['create_base_extracted_entities']
2024-10-24 15:24:24,707 - graphrag.index.run - INFO - read table from storage: create_base_extracted_entities.parquet
2024-10-24 15:24:24,714 - datashaper.workflow.workflow - INFO - executing verb summarize_descriptions
2024-10-24 15:24:24,833 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_summarized_entities.parquet
2024-10-24 15:24:25,006 - graphrag.index.run - INFO - Running workflow: create_base_entity_graph...
2024-10-24 15:24:25,007 - graphrag.index.run - INFO - dependencies for create_base_entity_graph: ['create_summarized_entities']
2024-10-24 15:24:25,007 - graphrag.index.run - INFO - read table from storage: create_summarized_entities.parquet
2024-10-24 15:24:25,016 - datashaper.workflow.workflow - INFO - executing verb cluster_graph
2024-10-24 15:24:25,114 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:24:25,117 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_entity_graph.parquet
2024-10-24 15:24:25,300 - graphrag.index.run - INFO - Running workflow: create_final_entities...
2024-10-24 15:24:25,300 - graphrag.index.run - INFO - dependencies for create_final_entities: ['create_base_entity_graph']
2024-10-24 15:24:25,301 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 15:24:25,310 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 15:24:25,338 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:24:25,339 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:24:25,340 - datashaper.workflow.workflow - INFO - executing verb dedupe
2024-10-24 15:24:25,340 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:24:25,341 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 15:24:25,349 - datashaper.workflow.workflow - INFO - executing verb text_split
2024-10-24 15:24:25,356 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 15:24:25,357 - datashaper.workflow.workflow - INFO - executing verb merge
2024-10-24 15:24:25,422 - datashaper.workflow.workflow - INFO - executing verb text_embed
2024-10-24 15:24:25,424 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/openai/api/v2
2024-10-24 15:24:25,728 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
2024-10-24 15:24:25,729 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for text-embedding-3-small: 25
2024-10-24 15:24:25,747 - graphrag.index.verbs.text.embed.strategies.openai - INFO - embedding 286 inputs via 286 snippets using 18 batches. max_batch_size=16, max_tokens=8191
2024-10-24 15:24:27,487 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-24 15:24:27,634 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.8899999998975545. input_tokens=556, output_tokens=0
2024-10-24 15:24:27,647 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 15:24:27,648 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 15:24:27,656 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_entities.parquet
2024-10-24 15:24:27,914 - graphrag.index.run - INFO - Running workflow: create_final_nodes...
2024-10-24 15:24:27,914 - graphrag.index.run - INFO - dependencies for create_final_nodes: ['create_base_entity_graph']
2024-10-24 15:24:27,915 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 15:24:27,920 - datashaper.workflow.workflow - INFO - executing verb layout_graph
2024-10-24 15:24:28,030 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 15:24:28,059 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 15:24:28,088 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 15:24:28,089 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 15:24:28,099 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:24:28,099 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:24:28,100 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 15:24:28,103 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 15:24:28,111 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:24:28,113 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_nodes.parquet
2024-10-24 15:24:28,302 - graphrag.index.run - INFO - Running workflow: create_final_communities...
2024-10-24 15:24:28,303 - graphrag.index.run - INFO - dependencies for create_final_communities: ['create_base_entity_graph']
2024-10-24 15:24:28,303 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 15:24:28,307 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 15:24:28,334 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 15:24:28,360 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 15:24:28,363 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 15:24:28,370 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 15:24:28,379 - datashaper.workflow.workflow - INFO - executing verb concat
2024-10-24 15:24:28,379 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 15:24:28,411 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 15:24:28,417 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 15:24:28,423 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 15:24:28,428 - datashaper.workflow.workflow - INFO - executing verb fill
2024-10-24 15:24:28,428 - datashaper.workflow.workflow - INFO - executing verb merge
2024-10-24 15:24:28,435 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-24 15:24:28,436 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:24:28,438 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_communities.parquet
2024-10-24 15:24:28,638 - graphrag.index.run - INFO - Running workflow: join_text_units_to_entity_ids...
2024-10-24 15:24:28,639 - graphrag.index.run - INFO - dependencies for join_text_units_to_entity_ids: ['create_final_entities']
2024-10-24 15:24:28,640 - graphrag.index.run - INFO - read table from storage: create_final_entities.parquet
2024-10-24 15:24:28,668 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:24:28,669 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 15:24:28,671 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 15:24:28,677 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table join_text_units_to_entity_ids.parquet
2024-10-24 15:24:28,861 - graphrag.index.run - INFO - Running workflow: create_final_relationships...
2024-10-24 15:24:28,862 - graphrag.index.run - INFO - dependencies for create_final_relationships: ['create_base_entity_graph', 'create_final_nodes']
2024-10-24 15:24:28,862 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 15:24:28,866 - graphrag.index.run - INFO - read table from storage: create_final_nodes.parquet
2024-10-24 15:24:28,879 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 15:24:28,906 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 15:24:28,918 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:24:28,918 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 15:24:28,924 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 15:24:28,926 - datashaper.workflow.workflow - INFO - executing verb compute_edge_combined_degree
2024-10-24 15:24:28,930 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 15:24:28,930 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 15:24:28,934 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_relationships.parquet
2024-10-24 15:24:29,121 - graphrag.index.run - INFO - Running workflow: join_text_units_to_relationship_ids...
2024-10-24 15:24:29,122 - graphrag.index.run - INFO - dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
2024-10-24 15:24:29,122 - graphrag.index.run - INFO - read table from storage: create_final_relationships.parquet
2024-10-24 15:24:29,130 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:24:29,131 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 15:24:29,133 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 15:24:29,136 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:24:29,138 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table join_text_units_to_relationship_ids.parquet
2024-10-24 15:24:29,324 - graphrag.index.run - INFO - Running workflow: create_final_community_reports...
2024-10-24 15:24:29,324 - graphrag.index.run - INFO - dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes']
2024-10-24 15:24:29,325 - graphrag.index.run - INFO - read table from storage: create_final_relationships.parquet
2024-10-24 15:24:29,330 - graphrag.index.run - INFO - read table from storage: create_final_nodes.parquet
2024-10-24 15:24:29,336 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports_nodes
2024-10-24 15:24:29,347 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports_edges
2024-10-24 15:24:29,353 - datashaper.workflow.workflow - INFO - executing verb restore_community_hierarchy
2024-10-24 15:24:29,359 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports
2024-10-24 15:24:29,360 - graphrag.index.verbs.graph.report.prepare_community_reports - INFO - Number of nodes at level=1 => 286
2024-10-24 15:24:29,420 - graphrag.index.verbs.graph.report.prepare_community_reports - INFO - Number of nodes at level=0 => 286
2024-10-24 15:24:29,481 - datashaper.workflow.workflow - INFO - executing verb create_community_reports
2024-10-24 15:24:48,644 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-24 15:24:48,650 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-24 15:24:48,651 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.chat "create_community_report" with 0 retries took 19.141000000061467. input_tokens=2173, output_tokens=650
2024-10-24 15:24:48,654 - datashaper.workflow.workflow - INFO - executing verb window
2024-10-24 15:24:48,657 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_community_reports.parquet
2024-10-24 15:24:48,859 - graphrag.index.run - INFO - Running workflow: create_final_text_units...
2024-10-24 15:24:48,859 - graphrag.index.run - INFO - dependencies for create_final_text_units: ['create_base_text_units', 'join_text_units_to_entity_ids', 'join_text_units_to_relationship_ids']
2024-10-24 15:24:48,860 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-24 15:24:48,864 - graphrag.index.run - INFO - read table from storage: join_text_units_to_entity_ids.parquet
2024-10-24 15:24:48,872 - graphrag.index.run - INFO - read table from storage: join_text_units_to_relationship_ids.parquet
2024-10-24 15:24:48,883 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:24:48,884 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:24:48,885 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 15:24:48,891 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 15:24:48,898 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 15:24:48,900 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:24:48,903 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_text_units.parquet
2024-10-24 15:24:49,082 - graphrag.index.run - INFO - Running workflow: create_base_documents...
2024-10-24 15:24:49,083 - graphrag.index.run - INFO - dependencies for create_base_documents: ['create_final_text_units']
2024-10-24 15:24:49,083 - graphrag.index.run - INFO - read table from storage: create_final_text_units.parquet
2024-10-24 15:24:49,092 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 15:24:49,094 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 15:24:49,095 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:24:49,096 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 15:24:49,101 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 15:24:49,102 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 15:24:49,108 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:24:49,109 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 15:24:49,112 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_documents.parquet
2024-10-24 15:24:49,298 - graphrag.index.run - INFO - Running workflow: create_final_documents...
2024-10-24 15:24:49,298 - graphrag.index.run - INFO - dependencies for create_final_documents: ['create_base_documents']
2024-10-24 15:24:49,298 - graphrag.index.run - INFO - read table from storage: create_base_documents.parquet
2024-10-24 15:24:49,308 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 15:24:49,309 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_documents.parquet
2024-10-24 15:24:49,356 - graphrag_api.index - INFO - All workflows completed successfully.
2024-10-24 15:26:24,091 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT chunk_id IF NOT EXISTS FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT chunk_id FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique'
2024-10-24 15:26:24,094 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT document_id IF NOT EXISTS FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT document_id FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint document_id if not exists for (d:__Document__) require d.id is unique'
2024-10-24 15:26:24,096 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (c:__Community__) require c.community is unique'
2024-10-24 15:26:24,100 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (e:__Entity__) require e.id is unique'
2024-10-24 15:26:24,102 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Entity__) require e.name is unique'
2024-10-24 15:26:24,104 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Covariate__) REQUIRE (e.title) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Covariate__) require e.title is unique'
2024-10-24 15:26:24,107 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT related_id IF NOT EXISTS FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT related_id FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique'
2024-10-24 15:26:24,110 - root - INFO - Deleted folder: ./rag\output\20241024-150608
2024-10-24 15:38:26,791 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT chunk_id IF NOT EXISTS FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT chunk_id FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique'
2024-10-24 15:38:26,795 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT document_id IF NOT EXISTS FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT document_id FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint document_id if not exists for (d:__Document__) require d.id is unique'
2024-10-24 15:38:26,797 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (c:__Community__) require c.community is unique'
2024-10-24 15:38:26,799 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (e:__Entity__) require e.id is unique'
2024-10-24 15:38:26,804 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Entity__) require e.name is unique'
2024-10-24 15:38:26,807 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Covariate__) REQUIRE (e.title) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Covariate__) require e.title is unique'
2024-10-24 15:38:26,810 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT related_id IF NOT EXISTS FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT related_id FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique'
2024-10-24 15:50:29,557 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT chunk_id IF NOT EXISTS FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT chunk_id FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique'
2024-10-24 15:50:29,559 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT document_id IF NOT EXISTS FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT document_id FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint document_id if not exists for (d:__Document__) require d.id is unique'
2024-10-24 15:50:29,561 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (c:__Community__) require c.community is unique'
2024-10-24 15:50:29,563 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (e:__Entity__) require e.id is unique'
2024-10-24 15:50:29,565 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Entity__) require e.name is unique'
2024-10-24 15:50:29,569 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Covariate__) REQUIRE (e.title) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Covariate__) require e.title is unique'
2024-10-24 15:50:29,570 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT related_id IF NOT EXISTS FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT related_id FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique'
2024-10-24 16:02:31,765 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT chunk_id IF NOT EXISTS FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT chunk_id FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique'
2024-10-24 16:02:31,768 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT document_id IF NOT EXISTS FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT document_id FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint document_id if not exists for (d:__Document__) require d.id is unique'
2024-10-24 16:02:31,771 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (c:__Community__) require c.community is unique'
2024-10-24 16:02:31,774 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (e:__Entity__) require e.id is unique'
2024-10-24 16:02:31,776 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Entity__) require e.name is unique'
2024-10-24 16:02:31,778 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Covariate__) REQUIRE (e.title) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Covariate__) require e.title is unique'
2024-10-24 16:02:31,781 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT related_id IF NOT EXISTS FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT related_id FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique'
2024-10-24 16:14:33,388 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT chunk_id IF NOT EXISTS FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT chunk_id FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique'
2024-10-24 16:14:33,390 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT document_id IF NOT EXISTS FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT document_id FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint document_id if not exists for (d:__Document__) require d.id is unique'
2024-10-24 16:14:33,392 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (c:__Community__) require c.community is unique'
2024-10-24 16:14:33,393 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (e:__Entity__) require e.id is unique'
2024-10-24 16:14:33,395 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Entity__) require e.name is unique'
2024-10-24 16:14:33,397 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Covariate__) REQUIRE (e.title) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Covariate__) require e.title is unique'
2024-10-24 16:14:33,398 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT related_id IF NOT EXISTS FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT related_id FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique'
2024-10-24 16:26:37,621 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT chunk_id IF NOT EXISTS FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT chunk_id FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique'
2024-10-24 16:26:37,624 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT document_id IF NOT EXISTS FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT document_id FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint document_id if not exists for (d:__Document__) require d.id is unique'
2024-10-24 16:26:37,630 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (c:__Community__) require c.community is unique'
2024-10-24 16:26:37,632 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (e:__Entity__) require e.id is unique'
2024-10-24 16:26:37,635 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Entity__) require e.name is unique'
2024-10-24 16:26:37,638 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Covariate__) REQUIRE (e.title) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Covariate__) require e.title is unique'
2024-10-24 16:26:37,640 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT related_id IF NOT EXISTS FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT related_id FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique'
2024-10-24 16:38:39,852 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT chunk_id IF NOT EXISTS FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT chunk_id FOR (e:__Chunk__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint chunk_id if not exists for (c:__Chunk__) require c.id is unique'
2024-10-24 16:38:39,858 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT document_id IF NOT EXISTS FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT document_id FOR (e:__Document__) REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint document_id if not exists for (d:__Document__) require d.id is unique'
2024-10-24 16:38:39,863 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (c:__Community__) require c.community is unique'
2024-10-24 16:38:39,869 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_id IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_id FOR (e:__Community__) REQUIRE (e.community) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_id if not exists for (e:__Entity__) require e.id is unique'
2024-10-24 16:38:39,872 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Entity__) require e.name is unique'
2024-10-24 16:38:39,874 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT entity_title IF NOT EXISTS FOR (e:__Covariate__) REQUIRE (e.title) IS UNIQUE` has no effect.} {description: `CONSTRAINT entity_title FOR (e:__Entity__) REQUIRE (e.name) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint entity_title if not exists for (e:__Covariate__) require e.title is unique'
2024-10-24 16:38:39,880 - neo4j.notifications - INFO - Received notification from DBMS server: {severity: INFORMATION} {code: Neo.ClientNotification.Schema.IndexOrConstraintAlreadyExists} {category: SCHEMA} {title: `CREATE CONSTRAINT related_id IF NOT EXISTS FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` has no effect.} {description: `CONSTRAINT related_id FOR ()-[e:RELATED]-() REQUIRE (e.id) IS UNIQUE` already exists.} {position: None} for query: '  \n        create constraint related_id if not exists for ()-[rel:RELATED]->() require rel.id is unique'
2024-10-24 16:44:13,115 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-24 16:44:13,115 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-24 16:44:23,675 - werkzeug - INFO - [31m[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.[0m
 * Running on all addresses (0.0.0.0)
 * Running on http://127.0.0.1:6240
 * Running on http://198.18.0.1:6240
2024-10-24 16:44:23,675 - werkzeug - INFO - [33mPress CTRL+C to quit[0m
2024-10-24 16:44:43,889 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-24 16:44:45,574 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-24 16:44:46,247 - graphrag.query.context_builder.community_context - INFO - Computing community weights...
2024-10-24 16:44:55,110 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-24 16:44:55,125 - graphrag.query.structured_search.global_search.search - INFO - Map response: {
    "points": [
        {"description": "RAG£¨Relevance, Accuracy, and Granularity£©ÏµÍ³ÊÇÒ»ÖÖÓÃÓÚÆÀ¹ÀÐÅÏ¢¼ìË÷ÏµÍ³ÐÔÄÜµÄ·½·¨¡£ÒªÊµÏÖÒ»¸öRAGÏµÍ³£¬Ê×ÏÈÐèÒª¶¨ÒåÆÀ¹ÀµÄÈý¸öÎ¬¶È£ºÏà¹ØÐÔ¡¢×¼È·ÐÔºÍÁ£¶È¡£", "score": 80},
        {"description": "Ïà¹ØÐÔ£¨Relevance£©Ö¸µÄÊÇ¼ìË÷½á¹ûÓëÓÃ»§²éÑ¯µÄÆ¥Åä³Ì¶È¡£¿ÉÒÔÍ¨¹ý¼ÆËã²éÑ¯ÓëÎÄµµÖ®¼äµÄÏàËÆ¶ÈÀ´ÊµÏÖ¡£¿ÉÒÔÊ¹ÓÃÖîÈçTF-IDF¡¢BM25µÈÏàËÆ¶È¼ÆËã·½·¨¡£", "score": 70},
        {"description": "×¼È·ÐÔ£¨Accuracy£©Ö¸µÄÊÇ¼ìË÷½á¹ûÖÐ°üº¬ÕýÈ·´ð°¸µÄ±ÈÀý¡£¿ÉÒÔÍ¨¹ý±È½Ï¼ìË÷½á¹ûÓëÈË¹¤±ê×¢µÄ´ð°¸À´ÊµÏÖ¡£ÕâÍ¨³£ÐèÒªÈË¹¤±ê×¢Êý¾Ý¼¯¡£", "score": 60},
        {"description": "Á£¶È£¨Granularity£©Ö¸µÄÊÇ¼ìË÷½á¹ûÖÐÐÅÏ¢µÄÏêÏ¸³Ì¶È¡£ÀýÈç£¬Ò»¸öÏµÍ³¿ÉÄÜ·µ»ØÕû¸öÎÄµµ£¬Ò²¿ÉÄÜÖ»·µ»ØÎÄµµÖÐµÄÄ³¸ö¶ÎÂä»ò¾ä×Ó¡£Á£¶È¿ÉÒÔ¸ù¾ÝÓÃ»§ÐèÇó½øÐÐµ÷Õû¡£", "score": 50},
        {"description": "ÊµÏÖRAGÏµÍ³ÐèÒªÒÔÏÂ²½Öè£ºÊÕ¼¯Êý¾Ý¡¢¹¹½¨Ë÷Òý¡¢Éè¼Æ²éÑ¯´¦ÀíÂß¼­¡¢ÆÀ¹ÀÐÔÄÜ¡£¾ßÌåÀ´Ëµ£¬°üÀ¨£º1. ÊÕ¼¯Ïà¹ØÊý¾Ý¼¯£»2. ¹¹½¨µ¹ÅÅË÷Òý£»3. Éè¼Æ²éÑ¯´¦ÀíÂß¼­£¬°üÀ¨Ïà¹ØÐÔ¼ÆËã¡¢×¼È·ÐÔÆÀ¹ÀºÍÁ£¶Èµ÷Õû£»4. Ê¹ÓÃÈË¹¤±ê×¢Êý¾Ý¼¯ÆÀ¹ÀÏµÍ³ÐÔÄÜ¡£", "score": 90}
    ]
}
2024-10-24 16:45:02,023 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-24 16:45:02,025 - graphrag.query.structured_search.global_search.search - INFO - Map response: ```json
{
    "points": [
        {"description": "Agione.AI ÊÇ AI Á÷³ÌÉçÇøµÄÖÐÐÄÊµÌå£¬Ìá¹© AI ÏµÍ³Æ½Ì¨ºÍ¶àÖÖ AI Á÷³Ì¡£ÉçÇø°üÀ¨ AI Á÷³ÌºÍ²ÎÓëÆä¿ª·¢µÄ¸öÈË£¬¹ØÏµ±íÃ÷ÁË AI ÏµÍ³Æ½Ì¨µÄÊ¹ÓÃºÍ Agione.AI Ìá¹©µÄ·þÎñ¡£[Data: Entities (188), Relationships (146, 159, 160, 161, 162, 163, 164, +more)]", "score": 80},
        {"description": "AI Á÷³ÌÊÇÉçÇøµÄ¹Ø¼ü×é³É²¿·Ö£¬ÓÉ Agione.AI ¿ª·¢²¢Ìá¹©¡£ÕâÐ©Á÷³Ì¶ÔÓÚÉçÇøµÄÕûÌå½á¹¹ÖÁ¹ØÖØÒª¡£[Data: Entities (179, 183, 181, 180, 182); Relationships (15, 19, 17, 16, 18, +more)]", "score": 70},
        {"description": "Lin ²ÎÓëÁË General Scraper LV1 Á÷³Ì£¬Õâ±íÃ÷ Lin ÔÚ AI Á÷³ÌµÄ¿ª·¢ºÍÎ¬»¤ÖÐ°çÑÝ×ÅÖØÒª½ÇÉ«¡£[Data: Entities (187, 188); Relationships (158, +more)]", "score": 60},
        {"description": "ÉçÇøÖÐµÄ¶à¸ö AI Á÷³ÌÊ¹ÓÃ Agione.AI Ìá¹©µÄ AI ÏµÍ³Æ½Ì¨£¬Õâ±íÃ÷Æ½Ì¨¶ÔÓÚÉçÇøµÄ²Ù×÷ÖÁ¹ØÖØÒª¡£[Data: Relationships (15, 19, 17, 16, 18, +more)]", "score": 50},
        {"description": "Agione.AI ÓëÓéÀÖÐÐÒµÓÐ¹Ø£¬Õâ±íÃ÷Æä AI ¼¼Êõ¿ÉÄÜ¶ÔÓéÀÖÐÐÒµ²úÉúÖØ´óÓ°Ïì¡£[Data: Entities (188); Relationships (164, +more)]", "score": 40}
    ]
}
```
2024-10-24 16:45:02,025 - graphrag.llm.openai.utils - INFO - Warning: Error decoding faulty json, attempting repair
2024-10-24 16:45:07,580 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-24 16:45:07,731 - werkzeug - INFO - 127.0.0.1 - - [24/Oct/2024 16:45:07] "POST /graphrag/chat HTTP/1.1" 200 -
2024-10-24 16:45:30,975 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-24 16:45:32,331 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-24 16:45:34,145 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-24 16:45:34,213 - graphrag.query.structured_search.local_search.search - INFO - GENERATE ANSWER: 1729759533.156645. QUERY: ÔõÃ´ÊµÏÖÒ»¸öragÏµÍ³
2024-10-24 16:45:39,742 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-24 16:45:46,102 - werkzeug - INFO - 127.0.0.1 - - [24/Oct/2024 16:45:46] "POST /graphrag/chat HTTP/1.1" 200 -
2024-10-24 16:46:12,344 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-24 16:46:13,691 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-24 16:46:15,297 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-24 16:46:15,391 - graphrag.query.structured_search.local_search.search - INFO - GENERATE ANSWER: 1729759574.3918004. QUERY: ÔõÃ´ÊµÏÖÒ»¸öragÏµÍ³
2024-10-24 16:46:20,604 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/zhipu/api/v2/chat/completions/chat/completions "HTTP/1.1 200 OK"
2024-10-24 16:46:24,894 - werkzeug - INFO - 127.0.0.1 - - [24/Oct/2024 16:46:24] "POST /graphrag/chat HTTP/1.1" 200 -
2024-10-24 16:54:30,495 - graphrag.config.read_dotenv - INFO - Loading pipeline .env file
2024-10-24 16:54:30,503 - graphrag_api.index - INFO - Logging enabled at rag\output\20241024-165430\reports\indexing-engine.log
2024-10-24 16:54:30,507 - graphrag_api.index - INFO - Starting pipeline run for: 20241024-165430, self.dryrun=False
2024-10-24 16:54:30,507 - graphrag_api.index - INFO - Using default configuration: {
    "llm": {
        "api_key": "==== REDACTED ====",
        "type": "openai_chat",
        "model": "glm-4-flash",
        "max_tokens": 4000,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "request_timeout": 180.0,
        "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
        "api_version": null,
        "proxy": null,
        "cognitive_services_endpoint": null,
        "deployment_name": null,
        "model_supports_json": true,
        "tokens_per_minute": 0,
        "requests_per_minute": 0,
        "max_retries": 10,
        "max_retry_wait": 10.0,
        "sleep_on_rate_limit_recommendation": true,
        "concurrent_requests": 25
    },
    "parallelization": {
        "stagger": 0.3,
        "num_threads": 50
    },
    "async_mode": "threaded",
    "root_dir": "rag",
    "reporting": {
        "type": "file",
        "base_dir": "output/${timestamp}/reports",
        "storage_account_blob_url": null
    },
    "storage": {
        "type": "file",
        "base_dir": "output/${timestamp}/artifacts",
        "storage_account_blob_url": null
    },
    "cache": {
        "type": "file",
        "base_dir": "cache",
        "storage_account_blob_url": null
    },
    "input": {
        "type": "file",
        "file_type": "text",
        "base_dir": "input",
        "storage_account_blob_url": null,
        "encoding": "utf-8",
        "file_pattern": ".*\\.txt$",
        "file_filter": null,
        "source_column": null,
        "timestamp_column": null,
        "timestamp_format": null,
        "text_column": "text",
        "title_column": null,
        "document_attribute_columns": []
    },
    "embed_graph": {
        "enabled": false,
        "num_walks": 10,
        "walk_length": 40,
        "window_size": 2,
        "iterations": 3,
        "random_seed": 597832,
        "strategy": null
    },
    "embeddings": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_embedding",
            "model": "text-embedding-3-small",
            "max_tokens": 4000,
            "temperature": 0,
            "top_p": 1,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/openai/api/v2",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": null,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "batch_size": 16,
        "batch_max_tokens": 8191,
        "target": "required",
        "skip": [],
        "vector_store": null,
        "strategy": null
    },
    "chunks": {
        "size": 1200,
        "overlap": 100,
        "group_by_columns": [
            "id"
        ],
        "strategy": null,
        "encoding_model": null
    },
    "snapshots": {
        "graphml": false,
        "raw_entities": false,
        "top_level_nodes": false
    },
    "entity_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/entity_extraction.txt",
        "entity_types": [
            "organization",
            "person",
            "geo",
            "event"
        ],
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "summarize_descriptions": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/summarize_descriptions.txt",
        "max_length": 500,
        "strategy": null
    },
    "community_reports": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "prompt": "prompts/community_report.txt",
        "max_length": 2000,
        "max_input_length": 8000,
        "strategy": null
    },
    "claim_extraction": {
        "llm": {
            "api_key": "==== REDACTED ====",
            "type": "openai_chat",
            "model": "glm-4-flash",
            "max_tokens": 4000,
            "temperature": 0.0,
            "top_p": 1.0,
            "n": 1,
            "request_timeout": 180.0,
            "api_base": "https://gateway.agione.ai/zhipu/api/v2/chat/completions",
            "api_version": null,
            "proxy": null,
            "cognitive_services_endpoint": null,
            "deployment_name": null,
            "model_supports_json": true,
            "tokens_per_minute": 0,
            "requests_per_minute": 0,
            "max_retries": 10,
            "max_retry_wait": 10.0,
            "sleep_on_rate_limit_recommendation": true,
            "concurrent_requests": 25
        },
        "parallelization": {
            "stagger": 0.3,
            "num_threads": 50
        },
        "async_mode": "threaded",
        "enabled": false,
        "prompt": "prompts/claim_extraction.txt",
        "description": "Any claims or facts that could be relevant to information discovery.",
        "max_gleanings": 1,
        "strategy": null,
        "encoding_model": null
    },
    "cluster_graph": {
        "max_cluster_size": 10,
        "strategy": null
    },
    "umap": {
        "enabled": false
    },
    "local_search": {
        "text_unit_prop": 0.5,
        "community_prop": 0.1,
        "conversation_history_max_turns": 5,
        "top_k_entities": 10,
        "top_k_relationships": 10,
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "llm_max_tokens": 2000
    },
    "global_search": {
        "temperature": 0.0,
        "top_p": 1.0,
        "n": 1,
        "max_tokens": 12000,
        "data_max_tokens": 12000,
        "map_max_tokens": 1000,
        "reduce_max_tokens": 2000,
        "concurrency": 32
    },
    "encoding_model": "cl100k_base",
    "skip_workflows": []
}
2024-10-24 16:54:30,509 - graphrag.index.create_pipeline_config - INFO - skipping workflows 
2024-10-24 16:54:30,509 - graphrag.index.run - INFO - Running pipeline
2024-10-24 16:54:30,509 - graphrag.index.storage.file_pipeline_storage - INFO - Creating file storage at rag\output\20241024-165430\artifacts
2024-10-24 16:54:30,509 - graphrag.index.input.load_input - INFO - loading input from root_dir=input
2024-10-24 16:54:30,509 - graphrag.index.input.load_input - INFO - using file storage for input
2024-10-24 16:54:30,510 - graphrag.index.storage.file_pipeline_storage - INFO - search rag\input for files matching .*\.txt$
2024-10-24 16:54:30,510 - graphrag.index.input.text - INFO - found text files from input, found [('input.txt', {})]
2024-10-24 16:54:30,515 - graphrag.index.input.text - INFO - Found 1 files, loading 1
2024-10-24 16:54:30,516 - graphrag.index.workflows.load - INFO - Workflow Run Order: ['create_base_text_units', 'create_base_extracted_entities', 'create_summarized_entities', 'create_base_entity_graph', 'create_final_entities', 'create_final_nodes', 'create_final_communities', 'join_text_units_to_entity_ids', 'create_final_relationships', 'join_text_units_to_relationship_ids', 'create_final_community_reports', 'create_final_text_units', 'create_base_documents', 'create_final_documents']
2024-10-24 16:54:30,516 - graphrag.index.run - INFO - Final # of rows loaded: 1
2024-10-24 16:54:30,704 - graphrag.index.run - INFO - Running workflow: create_base_text_units...
2024-10-24 16:54:30,705 - graphrag.index.run - INFO - dependencies for create_base_text_units: []
2024-10-24 16:54:30,705 - datashaper.workflow.workflow - INFO - executing verb orderby
2024-10-24 16:54:30,706 - datashaper.workflow.workflow - INFO - executing verb zip
2024-10-24 16:54:30,708 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 16:54:30,710 - datashaper.workflow.workflow - INFO - executing verb chunk
2024-10-24 16:54:30,906 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 16:54:30,907 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 16:54:30,910 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 16:54:30,911 - datashaper.workflow.workflow - INFO - executing verb genid
2024-10-24 16:54:30,913 - datashaper.workflow.workflow - INFO - executing verb unzip
2024-10-24 16:54:30,915 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-24 16:54:30,915 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 16:54:30,924 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_text_units.parquet
2024-10-24 16:54:31,120 - graphrag.index.run - INFO - Running workflow: create_base_extracted_entities...
2024-10-24 16:54:31,120 - graphrag.index.run - INFO - dependencies for create_base_extracted_entities: ['create_base_text_units']
2024-10-24 16:54:31,121 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-24 16:54:31,131 - datashaper.workflow.workflow - INFO - executing verb entity_extract
2024-10-24 16:54:31,136 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/zhipu/api/v2/chat/completions
2024-10-24 16:54:31,419 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for glm-4-flash: TPM=0, RPM=0
2024-10-24 16:54:31,419 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for glm-4-flash: 25
2024-10-24 16:54:31,494 - datashaper.workflow.workflow - INFO - executing verb merge_graphs
2024-10-24 16:54:31,526 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_extracted_entities.parquet
2024-10-24 16:54:31,712 - graphrag.index.run - INFO - Running workflow: create_summarized_entities...
2024-10-24 16:54:31,713 - graphrag.index.run - INFO - dependencies for create_summarized_entities: ['create_base_extracted_entities']
2024-10-24 16:54:31,714 - graphrag.index.run - INFO - read table from storage: create_base_extracted_entities.parquet
2024-10-24 16:54:31,724 - datashaper.workflow.workflow - INFO - executing verb summarize_descriptions
2024-10-24 16:54:31,866 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_summarized_entities.parquet
2024-10-24 16:54:32,047 - graphrag.index.run - INFO - Running workflow: create_base_entity_graph...
2024-10-24 16:54:32,047 - graphrag.index.run - INFO - dependencies for create_base_entity_graph: ['create_summarized_entities']
2024-10-24 16:54:32,048 - graphrag.index.run - INFO - read table from storage: create_summarized_entities.parquet
2024-10-24 16:54:32,059 - datashaper.workflow.workflow - INFO - executing verb cluster_graph
2024-10-24 16:54:32,159 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 16:54:32,161 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_entity_graph.parquet
2024-10-24 16:54:32,344 - graphrag.index.run - INFO - Running workflow: create_final_entities...
2024-10-24 16:54:32,345 - graphrag.index.run - INFO - dependencies for create_final_entities: ['create_base_entity_graph']
2024-10-24 16:54:32,346 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 16:54:32,356 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 16:54:32,385 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 16:54:32,386 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 16:54:32,386 - datashaper.workflow.workflow - INFO - executing verb dedupe
2024-10-24 16:54:32,387 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 16:54:32,387 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 16:54:32,394 - datashaper.workflow.workflow - INFO - executing verb text_split
2024-10-24 16:54:32,402 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 16:54:32,403 - datashaper.workflow.workflow - INFO - executing verb merge
2024-10-24 16:54:32,469 - datashaper.workflow.workflow - INFO - executing verb text_embed
2024-10-24 16:54:32,470 - graphrag.llm.openai.create_openai_client - INFO - Creating OpenAI client base_url=https://gateway.agione.ai/openai/api/v2
2024-10-24 16:54:32,752 - graphrag.index.llm.load_llm - INFO - create TPM/RPM limiter for text-embedding-3-small: TPM=0, RPM=0
2024-10-24 16:54:32,752 - graphrag.index.llm.load_llm - INFO - create concurrency limiter for text-embedding-3-small: 25
2024-10-24 16:54:32,773 - graphrag.index.verbs.text.embed.strategies.openai - INFO - embedding 286 inputs via 286 snippets using 18 batches. max_batch_size=16, max_tokens=8191
2024-10-24 16:54:34,086 - httpx - INFO - HTTP Request: POST https://gateway.agione.ai/openai/api/v2/embeddings "HTTP/1.1 200 OK"
2024-10-24 16:54:34,247 - graphrag.llm.base.rate_limiting_llm - INFO - perf - llm.embedding "Process" with 0 retries took 1.4690000000409782. input_tokens=556, output_tokens=0
2024-10-24 16:54:34,259 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 16:54:34,260 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 16:54:34,265 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_entities.parquet
2024-10-24 16:54:34,412 - graphrag.index.run - INFO - Running workflow: create_final_nodes...
2024-10-24 16:54:34,413 - graphrag.index.run - INFO - dependencies for create_final_nodes: ['create_base_entity_graph']
2024-10-24 16:54:34,413 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 16:54:34,416 - datashaper.workflow.workflow - INFO - executing verb layout_graph
2024-10-24 16:54:34,484 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 16:54:34,502 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 16:54:34,520 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 16:54:34,521 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 16:54:34,527 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 16:54:34,527 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 16:54:34,527 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 16:54:34,532 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 16:54:34,533 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 16:54:34,535 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_nodes.parquet
2024-10-24 16:54:34,634 - graphrag.index.run - INFO - Running workflow: create_final_communities...
2024-10-24 16:54:34,634 - graphrag.index.run - INFO - dependencies for create_final_communities: ['create_base_entity_graph']
2024-10-24 16:54:34,635 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 16:54:34,638 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 16:54:34,653 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 16:54:34,667 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 16:54:34,669 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 16:54:34,674 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 16:54:34,677 - datashaper.workflow.workflow - INFO - executing verb concat
2024-10-24 16:54:34,677 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 16:54:34,695 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 16:54:34,698 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 16:54:34,701 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 16:54:34,704 - datashaper.workflow.workflow - INFO - executing verb fill
2024-10-24 16:54:34,704 - datashaper.workflow.workflow - INFO - executing verb merge
2024-10-24 16:54:34,707 - datashaper.workflow.workflow - INFO - executing verb copy
2024-10-24 16:54:34,708 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 16:54:34,709 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_communities.parquet
2024-10-24 16:54:34,820 - graphrag.index.run - INFO - Running workflow: join_text_units_to_entity_ids...
2024-10-24 16:54:34,820 - graphrag.index.run - INFO - dependencies for join_text_units_to_entity_ids: ['create_final_entities']
2024-10-24 16:54:34,820 - graphrag.index.run - INFO - read table from storage: create_final_entities.parquet
2024-10-24 16:54:34,840 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 16:54:34,840 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 16:54:34,841 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 16:54:34,844 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table join_text_units_to_entity_ids.parquet
2024-10-24 16:54:34,943 - graphrag.index.run - INFO - Running workflow: create_final_relationships...
2024-10-24 16:54:34,944 - graphrag.index.run - INFO - dependencies for create_final_relationships: ['create_base_entity_graph', 'create_final_nodes']
2024-10-24 16:54:34,944 - graphrag.index.run - INFO - read table from storage: create_base_entity_graph.parquet
2024-10-24 16:54:34,947 - graphrag.index.run - INFO - read table from storage: create_final_nodes.parquet
2024-10-24 16:54:34,957 - datashaper.workflow.workflow - INFO - executing verb unpack_graph
2024-10-24 16:54:34,973 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 16:54:34,980 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 16:54:34,980 - datashaper.workflow.workflow - INFO - executing verb filter
2024-10-24 16:54:34,984 - datashaper.workflow.workflow - INFO - executing verb drop
2024-10-24 16:54:34,985 - datashaper.workflow.workflow - INFO - executing verb compute_edge_combined_degree
2024-10-24 16:54:34,988 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 16:54:34,989 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 16:54:34,989 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_relationships.parquet
2024-10-24 16:54:35,100 - graphrag.index.run - INFO - Running workflow: join_text_units_to_relationship_ids...
2024-10-24 16:54:35,100 - graphrag.index.run - INFO - dependencies for join_text_units_to_relationship_ids: ['create_final_relationships']
2024-10-24 16:54:35,100 - graphrag.index.run - INFO - read table from storage: create_final_relationships.parquet
2024-10-24 16:54:35,108 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 16:54:35,108 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 16:54:35,109 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 16:54:35,111 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 16:54:35,113 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table join_text_units_to_relationship_ids.parquet
2024-10-24 16:54:35,211 - graphrag.index.run - INFO - Running workflow: create_final_community_reports...
2024-10-24 16:54:35,212 - graphrag.index.run - INFO - dependencies for create_final_community_reports: ['create_final_relationships', 'create_final_nodes']
2024-10-24 16:54:35,212 - graphrag.index.run - INFO - read table from storage: create_final_relationships.parquet
2024-10-24 16:54:35,216 - graphrag.index.run - INFO - read table from storage: create_final_nodes.parquet
2024-10-24 16:54:35,219 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports_nodes
2024-10-24 16:54:35,226 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports_edges
2024-10-24 16:54:35,229 - datashaper.workflow.workflow - INFO - executing verb restore_community_hierarchy
2024-10-24 16:54:35,232 - datashaper.workflow.workflow - INFO - executing verb prepare_community_reports
2024-10-24 16:54:35,232 - graphrag.index.verbs.graph.report.prepare_community_reports - INFO - Number of nodes at level=1 => 286
2024-10-24 16:54:35,270 - graphrag.index.verbs.graph.report.prepare_community_reports - INFO - Number of nodes at level=0 => 286
2024-10-24 16:54:35,306 - datashaper.workflow.workflow - INFO - executing verb create_community_reports
2024-10-24 16:54:35,342 - datashaper.workflow.workflow - INFO - executing verb window
2024-10-24 16:54:35,344 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_community_reports.parquet
2024-10-24 16:54:35,455 - graphrag.index.run - INFO - Running workflow: create_final_text_units...
2024-10-24 16:54:35,456 - graphrag.index.run - INFO - dependencies for create_final_text_units: ['create_base_text_units', 'join_text_units_to_relationship_ids', 'join_text_units_to_entity_ids']
2024-10-24 16:54:35,456 - graphrag.index.run - INFO - read table from storage: create_base_text_units.parquet
2024-10-24 16:54:35,459 - graphrag.index.run - INFO - read table from storage: join_text_units_to_relationship_ids.parquet
2024-10-24 16:54:35,466 - graphrag.index.run - INFO - read table from storage: join_text_units_to_entity_ids.parquet
2024-10-24 16:54:35,475 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 16:54:35,475 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 16:54:35,476 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 16:54:35,480 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 16:54:35,483 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 16:54:35,485 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 16:54:35,487 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_text_units.parquet
2024-10-24 16:54:35,591 - graphrag.index.run - INFO - Running workflow: create_base_documents...
2024-10-24 16:54:35,591 - graphrag.index.run - INFO - dependencies for create_base_documents: ['create_final_text_units']
2024-10-24 16:54:35,592 - graphrag.index.run - INFO - read table from storage: create_final_text_units.parquet
2024-10-24 16:54:35,600 - datashaper.workflow.workflow - INFO - executing verb unroll
2024-10-24 16:54:35,600 - datashaper.workflow.workflow - INFO - executing verb select
2024-10-24 16:54:35,601 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 16:54:35,601 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 16:54:35,604 - datashaper.workflow.workflow - INFO - executing verb aggregate_override
2024-10-24 16:54:35,606 - datashaper.workflow.workflow - INFO - executing verb join
2024-10-24 16:54:35,609 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 16:54:35,609 - datashaper.workflow.workflow - INFO - executing verb convert
2024-10-24 16:54:35,611 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_base_documents.parquet
2024-10-24 16:54:35,702 - graphrag.index.run - INFO - Running workflow: create_final_documents...
2024-10-24 16:54:35,703 - graphrag.index.run - INFO - dependencies for create_final_documents: ['create_base_documents']
2024-10-24 16:54:35,703 - graphrag.index.run - INFO - read table from storage: create_base_documents.parquet
2024-10-24 16:54:35,712 - datashaper.workflow.workflow - INFO - executing verb rename
2024-10-24 16:54:35,713 - graphrag.index.emit.parquet_table_emitter - INFO - emitting parquet table create_final_documents.parquet
2024-10-24 16:54:35,742 - graphrag_api.index - INFO - All workflows completed successfully.
